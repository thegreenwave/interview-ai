import os
import time
import difflib
import numpy as np
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import plotly.express as px
import pdfplumber
from pdf2image import convert_from_bytes
import pytesseract
from collections import Counter
import json

# ==========================================
# ğŸ”‘ ê¸°ë³¸ ì„¤ì • ë° ìƒíƒœ ì´ˆê¸°í™”
# ==========================================
st.set_page_config(page_title="Spec-trum Pro", page_icon="ğŸ™ï¸", layout="wide")

# 1. í˜ì´ì§€ ë‹¨ê³„(Step) ì´ˆê¸°í™” (ìƒˆë¡œê³ ì¹¨ í•´ë„ ìœ ì§€ë¨)
if 'step' not in st.session_state:
    st.session_state.step = 'login'  # ì´ˆê¸° í™”ë©´: ë¡œê·¸ì¸

# 2. ë°ì´í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
if 'script' not in st.session_state: st.session_state.script = ""
if 'uni_questions' not in st.session_state: st.session_state.uni_questions = ""
if 'target_q' not in st.session_state: st.session_state.target_q = ""

# 3. í˜ì´ì§€ ì´ë™ í•¨ìˆ˜ (í™”ë©´ ì „í™˜ì˜ í•µì‹¬)
def go_to(page_name):
    st.session_state.step = page_name
    st.rerun()  # í™”ë©´ì„ ì¦‰ì‹œ ìƒˆë¡œê³ ì¹¨í•´ì„œ ì´ì „ í™”ë©´ì„ ì§€ì›€

# 4. API í‚¤ ì„¤ì •
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
client = OpenAI()

# ==========================================
# ğŸ“Š ë¶„ì„ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼)
# ==========================================
def extract_text_from_pdf(pdf_file):
    text = ""
    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                extracted = page.extract_text()
                if extracted: text += extracted + "\n"
    except: pass

    if len(text) < 50:
        st.toast("âš ï¸ ì´ë¯¸ì§€ PDF ê°ì§€! OCR ë³€í™˜ ì¤‘...")
        pdf_file.seek(0)
        try:
            images = convert_from_bytes(pdf_file.read())
            text = ""
            for image in images:
                page_text = pytesseract.image_to_string(image, lang='kor+eng')
                text += page_text + "\n"
        except: return ""
    return text

def analyze_audio_features(y, sr):
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    non_silent = librosa.effects.split(y, top_db=25)
    non_silent_dur = sum([(e-s) for s,e in non_silent]) / sr
    total_dur = librosa.get_duration(y=y, sr=sr)
    if len(non_silent) > 0: init_silence = librosa.frames_to_time(non_silent[0][0], sr=sr)
    else: init_silence = 0
    silence_ratio = (total_dur - non_silent_dur) / total_dur if total_dur > 0 else 0
    return times, rms, cent, total_dur, silence_ratio, init_silence

def analyze_text_patterns(text):
    fillers = ["ìŒ", "ì–´", "ê·¸", "ë§‰", "ì´ì œ", "ì•½ê°„", "ì €", "ì‚¬ì‹¤"]
    cnt = {f: text.count(f) for f in fillers if text.count(f) > 0}
    return cnt, sum(cnt.values())

def calculate_similarity(t1, t2):
    return difflib.SequenceMatcher(None, t1, t2).ratio() * 100

# ==========================================
# ğŸ–¥ï¸ í˜ì´ì§€ë³„ í™”ë©´ êµ¬ì„± (Web Flow)
# ==========================================

# [PAGE 1] ë¡œê·¸ì¸ í™”ë©´
if st.session_state.step == 'login':
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.title("ğŸ”’ SPEC-TRUM")
        st.write("ì—­ëŸ‰ì„ ì¦ëª…í•˜ëŠ” ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•")
        pw = st.text_input("ì ‘ì† ë¹„ë°€ë²ˆí˜¸", type="password")
        
        if st.button("ë¡œê·¸ì¸", use_container_width=True):
            if pw == "0601":
                st.success("ë¡œê·¸ì¸ ì„±ê³µ!")
                time.sleep(0.5)
                go_to('main_menu') # ë©”ì¸ ë©”ë‰´ë¡œ ì´ë™
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")

# [PAGE 2] ë©”ì¸ ë©”ë‰´ (ê¸°ëŠ¥ ì„ íƒ)
elif st.session_state.step == 'main_menu':
    st.title("ğŸš€ ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”")
    st.write("ì–´ë–¤ ì—°ìŠµì„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("ğŸ¤ ë°œí‘œ ì¤€ë¹„")
        st.write("ì£¼ì œë§Œ ì£¼ë©´ ëŒ€ë³¸ ì‘ì„±ë¶€í„° í‰ê°€ê¹Œì§€!")
        if st.button("ë°œí‘œ ë§ˆìŠ¤í„° ì‹œì‘í•˜ê¸°", use_container_width=True):
            go_to('pres_input') # ë°œí‘œ ì…ë ¥ í™”ë©´ìœ¼ë¡œ ì´ë™

    with col2:
        st.info("ğŸ“ ìƒê¸°ë¶€ ë©´ì ‘")
        st.write("PDFë¥¼ ì˜¬ë¦¬ë©´ ë‚˜ë§Œì„ ìœ„í•œ ì§ˆë¬¸ ìƒì„±!")
        if st.button("ì‹¬ì¸µ ë©´ì ‘ ì‹œì‘í•˜ê¸°", use_container_width=True):
            go_to('inter_upload') # ë©´ì ‘ ì—…ë¡œë“œ í™”ë©´ìœ¼ë¡œ ì´ë™

# =========================================================
# ğŸ¤ [ë°œí‘œ íŠ¸ë™] 
# =========================================================

# [PAGE 3-1] ë°œí‘œ: ì •ë³´ ì…ë ¥
elif st.session_state.step == 'pres_input':
    st.title("ğŸ“ ë°œí‘œ ì •ë³´ ì…ë ¥")
    
    topic = st.text_input("ë°œí‘œ ì£¼ì œ", placeholder="ì˜ˆ: ìƒì„±í˜• AIì˜ ë¯¸ë˜")
    context = st.text_input("ìƒí™©", placeholder="ì˜ˆ: ìˆ˜í–‰í‰ê°€ 3ë¶„ ë°œí‘œ")
    req = st.text_area("ìš”êµ¬ì‚¬í•­", placeholder="ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°ë¡œ ì¨ì¤˜")
    
    c1, c2 = st.columns([1, 1])
    with c1:
        if st.button("â¬…ï¸ ì´ì „ (ë©”ì¸ë©”ë‰´)", use_container_width=True):
            go_to('main_menu')
    with c2:
        if st.button("âœ¨ ëŒ€ë³¸ ìƒì„± ë° ë‹¤ìŒ ë‹¨ê³„", type="primary", use_container_width=True):
            if not topic:
                st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("AIê°€ ëŒ€ë³¸ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    prompt = f"ì£¼ì œ:{topic}\nìƒí™©:{context}\nìš”êµ¬ì‚¬í•­:{req}\në°œí‘œëŒ€ë³¸ ì‘ì„±í•´ì¤˜."
                    res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role":"user", "content":prompt}])
                    st.session_state.script = res.choices[0].message.content
                    go_to('pres_result') # ê²°ê³¼ í™”ë©´ìœ¼ë¡œ ì´ë™

# [PAGE 3-2] ë°œí‘œ: ì—°ìŠµ ë° í‰ê°€
elif st.session_state.step == 'pres_result':
    st.title("ğŸ“Š ì‹¤ì „ ë°œí‘œ ì—°ìŠµ")
    
    # ìƒë‹¨: ëŒ€ë³¸ í™•ì¸
    with st.expander("ğŸ“„ ìƒì„±ëœ ëŒ€ë³¸ ë³´ê¸° (í´ë¦­)", expanded=False):
        st.text_area("ëŒ€ë³¸", st.session_state.script, height=200)

    st.write("ëŒ€ë³¸ì„ ë³´ë©° ë…¹ìŒí•˜ì„¸ìš”.")
    audio = st.audio_input("ë…¹ìŒ ì‹œì‘")
    
    if audio:
        with st.spinner("ì •ë°€ ë¶„ì„ ì¤‘..."):
            y, sr = librosa.load(audio, sr=None)
            times, rms, cent, tot_dur, _, _, _, _ = analyze_audio_features(y, sr)
            tempo = float(librosa.beat.beat_track(y=y, sr=sr)[0])
            
            audio.seek(0)
            transcript = client.audio.transcriptions.create(model="whisper-1", file=audio).text
            acc = calculate_similarity(st.session_state.script, transcript)
            
            # ê²°ê³¼ í‘œì‹œ
            m1, m2, m3 = st.columns(3)
            m1.metric("ì†ë„", f"{tempo:.0f} BPM")
            m2.metric("ì •í™•ë„", f"{acc:.1f}%")
            m3.metric("ì‹œê°„", f"{tot_dur:.1f}ì´ˆ")
            
            st.subheader("ë‹¤ì´ë‚´ë¯¹ìŠ¤ ê·¸ë˜í”„")
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=times, y=rms, fill='tozeroy', name='Volume'))
            st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")
    if st.button("â¬…ï¸ ì²˜ìŒìœ¼ë¡œ (ì£¼ì œ ë‹¤ì‹œ ì…ë ¥)", use_container_width=True):
        go_to('pres_input')


# =========================================================
# ğŸ“ [ë©´ì ‘ íŠ¸ë™]
# =========================================================

# [PAGE 4-1] ë©´ì ‘: íŒŒì¼ ì—…ë¡œë“œ
elif st.session_state.step == 'inter_upload':
    st.title("ğŸ“‚ ìƒê¸°ë¶€ ì—…ë¡œë“œ")
    
    uploaded = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")
    
    c1, c2 = st.columns([1, 1])
    with c1:
        if st.button("â¬…ï¸ ì´ì „ (ë©”ì¸ë©”ë‰´)", use_container_width=True):
            go_to('main_menu')
    with c2:
        if uploaded:
            if st.button("ğŸ¤– ì§ˆë¬¸ ìƒì„± ë° ë‹¤ìŒ ë‹¨ê³„", type="primary", use_container_width=True):
                with st.spinner("ìƒê¸°ë¶€ ë¶„ì„ ì¤‘..."):
                    text = extract_text_from_pdf(uploaded)
                    if len(text) > 50:
                        prompt = f"ìƒê¸°ë¶€ ë‚´ìš©:\n{text[:15000]}\në©´ì ‘ ì§ˆë¬¸ 3ê°œ ë§Œë“¤ì–´ì¤˜."
                        res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role":"user", "content":prompt}])
                        st.session_state.uni_questions = res.choices[0].message.content
                        go_to('inter_result')
                    else:
                        st.error("í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨.")
        else:
            st.info("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# [PAGE 4-2] ë©´ì ‘: ì‹¤ì „ ì—°ìŠµ
elif st.session_state.step == 'inter_result':
    st.title("ğŸ™ï¸ ì‹¤ì „ ë©´ì ‘ íŠ¸ë ˆì´ë‹")
    
    st.info("AIê°€ ìƒì„±í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.")
    st.write(st.session_state.uni_questions)
    
    st.markdown("---")
    target_q = st.text_input("ë‹µë³€í•  ì§ˆë¬¸ì„ ì…ë ¥/ë³µì‚¬í•˜ì„¸ìš”")
    audio = st.audio_input("ë‹µë³€ ë…¹ìŒ")
    
    if audio and target_q:
        with st.spinner("ë©´ì ‘ê´€ í‰ê°€ ì¤‘..."):
            audio.seek(0)
            transcript = client.audio.transcriptions.create(model="whisper-1", file=audio).text
            
            eval_prompt = f"ì§ˆë¬¸:{target_q}\në‹µë³€:{transcript}\ní‰ê°€í•­ëª©: ë…¼ë¦¬ì„±, ì§„ì •ì„±, ìì‹ ê°, ì í•©ì„±. JSON ì¶œë ¥."
            res = client.chat.completions.create(model="gpt-4o", messages=[{"role":"user", "content":eval_prompt}], response_format={"type":"json_object"})
            data = json.loads(res.choices[0].message.content)
            
            st.subheader("í‰ê°€ ê²°ê³¼")
            st.write(data.get('feedback'))
            
            # ì°¨íŠ¸
            cats = ['ë…¼ë¦¬', 'ì§„ì •', 'ìì‹ ', 'ì í•©']
            vals = [data.get('logic',0)*10, data.get('sincerity',0)*10, data.get('confidence',0)*10, data.get('suitability',0)*10]
            fig = go.Figure(data=go.Scatterpolar(r=vals, theta=cats, fill='toself'))
            fig.update_layout(polar=dict(radialaxis=dict(range=[0,100])), showlegend=False)
            st.plotly_chart(fig)

    st.markdown("---")
    if st.button("â¬…ï¸ ë‹¤ë¥¸ ìƒê¸°ë¶€ ì˜¬ë¦¬ê¸°", use_container_width=True):
        go_to('inter_upload')
