import os
import time
import difflib
import numpy as np
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import plotly.express as px
import pdfplumber
from pdf2image import convert_from_bytes
import pytesseract
from collections import Counter
import json

# ==========================================
# ğŸ”‘ ì„¤ì • & ì´ˆê¸°í™”
# ==========================================
st.set_page_config(page_title="Spec-trum Pro", page_icon="ğŸ™ï¸", layout="wide")

# 1. ë„¤ë¹„ê²Œì´ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'step' not in st.session_state: st.session_state.step = 'login'

# 2. ë°ì´í„° ê³µìœ ìš© ì„¸ì…˜ ìƒíƒœ
if 'script' not in st.session_state: st.session_state.script = ""  # ìƒì„±ëœ ëŒ€ë³¸ ì €ì¥ìš©

# 3. í™”ë©´ ì´ë™ í•¨ìˆ˜
def go_to(page):
    st.session_state.step = page
    st.rerun()

# 4. API í‚¤
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
client = OpenAI()

# ==========================================
# ğŸ“Š ë¶„ì„ ì—”ì§„ (í•¨ìˆ˜ë“¤)
# ==========================================
def analyze_audio_features(y, sr):
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    non_silent = librosa.effects.split(y, top_db=25)
    non_silent_dur = sum([(e-s) for s,e in non_silent]) / sr
    total_dur = librosa.get_duration(y=y, sr=sr)
    if len(non_silent) > 0: init_silence = librosa.frames_to_time(non_silent[0][0], sr=sr)
    else: init_silence = 0
    silence_ratio = (total_dur - non_silent_dur) / total_dur if total_dur > 0 else 0
    return times, rms, cent, total_dur, silence_ratio, init_silence

def extract_text_from_pdf(pdf_file):
    text = ""
    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                extracted = page.extract_text()
                if extracted: text += extracted + "\n"
    except: pass
    
    if len(text) < 50: # OCR fallback
        pdf_file.seek(0)
        try:
            images = convert_from_bytes(pdf_file.read())
            text = ""
            for image in images:
                text += pytesseract.image_to_string(image, lang='kor+eng') + "\n"
        except: pass
    return text

def calculate_similarity(t1, t2):
    return difflib.SequenceMatcher(None, t1, t2).ratio() * 100

# ==========================================
# ğŸ–¥ï¸ í™”ë©´ íë¦„ (Workflow)
# ==========================================

# [PAGE 1] ë¡œê·¸ì¸
if st.session_state.step == 'login':
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.title("ğŸ”’ SPEC-TRUM")
        st.write("ì—­ëŸ‰ ì „ë‹¬ì˜ ìŠ¤í™íŠ¸ëŸ¼ì„ ë„“íˆë‹¤")
        pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        if st.button("ë¡œê·¸ì¸", use_container_width=True):
            if pw == "0601":
                st.success("ì ‘ì† ì„±ê³µ!")
                time.sleep(0.5)
                go_to('main_menu')
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ ì˜¤ë¥˜")

# [PAGE 2] ë©”ì¸ ë©”ë‰´ (ëŒ€ë¶„ë¥˜)
elif st.session_state.step == 'main_menu':
    st.title("ğŸš€ ë©”ì¸ ë©”ë‰´")
    st.write("ì›í•˜ëŠ” íŠ¸ë ˆì´ë‹ ì½”ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    
    col1, col2 = st.columns(2)
    with col1:
        st.info("ğŸ¤ ë°œí‘œ ë§ˆìŠ¤í„°")
        if st.button("ë°œí‘œ ì¤€ë¹„ ë©”ë‰´ë¡œ ì´ë™", use_container_width=True):
            go_to('pres_menu')
    with col2:
        st.info("ğŸ“ ìƒê¸°ë¶€ ë©´ì ‘")
        if st.button("ë©´ì ‘ íŠ¸ë ˆì´ë‹ ì‹œì‘", use_container_width=True):
            go_to('inter_upload')

# =========================================================
# ğŸ¤ [ë°œí‘œ íŠ¸ë™] - ì„œë¸Œ ë©”ë‰´ ë° ë…ë¦½ ê¸°ëŠ¥ë“¤
# =========================================================

# [PAGE 3-0] ë°œí‘œ ì„œë¸Œ ë©”ë‰´ (3ê°€ì§€ ë…ë¦½ ê¸°ëŠ¥ ì„ íƒ)
elif st.session_state.step == 'pres_menu':
    st.title("ğŸ¤ ë°œí‘œ ì¤€ë¹„ ë©”ë‰´")
    st.write("í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    
    # 3ê°œì˜ ì¹´ë“œë¡œ ë‚˜ëˆ„ì–´ ë°°ì¹˜
    c1, c2, c3 = st.columns(3)
    
    with c1:
        st.markdown("#### ğŸ“ 1. ëŒ€ë³¸ ì‘ì„±")
        st.caption("ì£¼ì œë§Œ ì£¼ë©´ AIê°€ ì¨ì¤ë‹ˆë‹¤.")
        if st.button("ëŒ€ë³¸ ì‘ì„±ê¸° ì‹¤í–‰", use_container_width=True):
            go_to('pres_1_writer')
            
    with c2:
        st.markdown("#### ğŸ§ 2. ëŒ€ë³¸ í‰ê°€")
        st.caption("ë‚´ê°€ ì“´ ëŒ€ë³¸ì„ í”¼ë“œë°± ë°›ìŠµë‹ˆë‹¤.")
        if st.button("ëŒ€ë³¸ í‰ê°€ê¸° ì‹¤í–‰", use_container_width=True):
            go_to('pres_2_advisor')
            
    with c3:
        st.markdown("#### ğŸ“Š 3. ëŠ¥ë ¥ í‰ê°€")
        st.caption("ë…¹ìŒí•˜ê³  ì†ë„, ë°œìŒ, í†¤ ë¶„ì„.")
        if st.button("ëŠ¥ë ¥ ì¸¡ì •ê¸° ì‹¤í–‰", use_container_width=True):
            go_to('pres_3_analyst')
            
    st.markdown("---")
    if st.button("â¬…ï¸ ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True):
        go_to('main_menu')

# [PAGE 3-1] ëŒ€ë³¸ ì‘ì„±ê¸° (Writer)
elif st.session_state.step == 'pres_1_writer':
    st.title("ğŸ“ ë°œí‘œ ëŒ€ë³¸ ì‘ì„±ê¸°")
    
    topic = st.text_input("ì£¼ì œ", placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥ì˜ ìœ¤ë¦¬ì  ë¬¸ì œ")
    context = st.text_input("ìƒí™©", placeholder="ì˜ˆ: ìœ¤ë¦¬ ìˆ˜ì—… ë°œí‘œ")
    req = st.text_area("ìš”êµ¬ì‚¬í•­", placeholder="ì„œë¡ -ë³¸ë¡ -ê²°ë¡ , 3ë¶„ ë¶„ëŸ‰")
    
    if st.button("âœ¨ ëŒ€ë³¸ ìƒì„± (GPT-4o-mini)", type="primary", use_container_width=True):
        if topic:
            with st.spinner("ì‘ì„± ì¤‘..."):
                prompt = f"ì£¼ì œ:{topic}\nìƒí™©:{context}\nìš”êµ¬ì‚¬í•­:{req}\në°œí‘œëŒ€ë³¸ ì‘ì„±í•´ì¤˜."
                res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role":"user", "content":prompt}])
                st.session_state.script = res.choices[0].message.content # ìƒì„±ëœ ëŒ€ë³¸ ì „ì—­ ì €ì¥
                st.success("ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        else:
            st.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
    if st.session_state.script:
        st.text_area("ìƒì„±ëœ ëŒ€ë³¸ (ë³µì‚¬í•´ì„œ ì“°ì„¸ìš”)", st.session_state.script, height=300)
    
    st.markdown("---")
    if st.button("â¬…ï¸ ë°œí‘œ ë©”ë‰´ë¡œ ë³µê·€", use_container_width=True):
        go_to('pres_menu')

# [PAGE 3-2] ëŒ€ë³¸ í‰ê°€ê¸° (Advisor)
elif st.session_state.step == 'pres_2_advisor':
    st.title("ğŸ§ ëŒ€ë³¸ í”¼ë“œë°±")
    
    # ì´ì „ì— ìƒì„±í•œ ëŒ€ë³¸ì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë„£ì–´ì¤Œ
    default_text = st.session_state.script if st.session_state.script else ""
    user_script = st.text_area("í‰ê°€ë°›ì„ ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”", value=default_text, height=200)
    user_intent = st.text_input("ì˜ë„í•˜ëŠ” ë°” (ê°•ì¡°ì )")
    
    if st.button("ğŸš€ í”¼ë“œë°± ë°›ê¸°", type="primary", use_container_width=True):
        if user_script:
            with st.spinner("ë¶„ì„ ì¤‘..."):
                res = client.chat.completions.create(model="gpt-4o", messages=[{"role":"user", "content":f"ëŒ€ë³¸:{user_script}\nì˜ë„:{user_intent}\ní‰ê°€í•´ì¤˜."}])
                st.info(res.choices[0].message.content)
        else:
            st.warning("ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

    st.markdown("---")
    if st.button("â¬…ï¸ ë°œí‘œ ë©”ë‰´ë¡œ ë³µê·€", use_container_width=True):
        go_to('pres_menu')

# [PAGE 3-3] ëŠ¥ë ¥ í‰ê°€ê¸° (Analyst)
elif st.session_state.step == 'pres_3_analyst':
    st.title("ğŸ“Š ë°œí‘œ ëŠ¥ë ¥ ì •ë°€ ë¶„ì„")
    st.caption("ëŒ€ë³¸ì´ ìˆë‹¤ë©´ ì •í™•ë„ê°€ ì¸¡ì •ë˜ê³ , ì—†ìœ¼ë©´ ì†ë„ì™€ í†¤ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    ref_text = st.text_area("ê¸°ì¤€ ëŒ€ë³¸ (ì„ íƒì‚¬í•­ - ìˆìœ¼ë©´ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”)", value=st.session_state.script, height=100)
    audio = st.audio_input("ë…¹ìŒ ì‹œì‘")
    
    if audio:
        with st.spinner("6-Point ì •ë°€ ë¶„ì„ ì¤‘..."):
            y, sr = librosa.load(audio, sr=None)
            times, rms, cent, tot_dur, _, _, _, _ = analyze_audio_features(y, sr)
            tempo = float(librosa.beat.beat_track(y=y, sr=sr)[0])
            
            # STT
            audio.seek(0)
            transcript = client.audio.transcriptions.create(model="whisper-1", file=audio).text
            
            # ì •í™•ë„ (ëŒ€ë³¸ì´ ìˆì„ ë•Œë§Œ)
            acc = calculate_similarity(ref_text, transcript) if ref_text else 0.0
            
            # ëŒ€ì‹œë³´ë“œ
            m1, m2, m3 = st.columns(3)
            m1.metric("ì†ë„", f"{tempo:.0f} BPM", delta="110~130 ê¶Œì¥")
            m2.metric("ì •í™•ë„", f"{acc:.1f}%" if ref_text else "N/A")
            m3.metric("ì‹œê°„", f"{tot_dur:.1f}ì´ˆ")
            
            # ê·¸ë˜í”„
            st.subheader("ëª©ì†Œë¦¬ í¬ê¸° & í†¤ ë³€í™”")
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=times, y=rms, fill='tozeroy', name='Volume', line=dict(color='firebrick')))
            st.plotly_chart(fig, use_container_width=True)
            
            with st.expander("AIê°€ ì¸ì‹í•œ ë‚´ìš© ë³´ê¸°"):
                st.write(transcript)

    st.markdown("---")
    if st.button("â¬…ï¸ ë°œí‘œ ë©”ë‰´ë¡œ ë³µê·€", use_container_width=True):
        go_to('pres_menu')

# =========================================================
# ğŸ“ [ë©´ì ‘ íŠ¸ë™]
# =========================================================

# [PAGE 4-1] ìƒê¸°ë¶€ ì—…ë¡œë“œ
elif st.session_state.step == 'inter_upload':
    st.title("ğŸ“‚ ìƒê¸°ë¶€ ì—…ë¡œë“œ")
    uploaded = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")
    
    if uploaded:
        if st.button("ì§ˆë¬¸ ìƒì„± ë° ë‹¤ìŒ ë‹¨ê³„", type="primary", use_container_width=True):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                text = extract_text_from_pdf(uploaded)
                if len(text) > 50:
                    prompt = f"ìƒê¸°ë¶€ ë‚´ìš©:\n{text[:15000]}\në©´ì ‘ ì§ˆë¬¸ 3ê°œ ë§Œë“¤ì–´ì¤˜."
                    res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role":"user", "content":prompt}])
                    st.session_state.uni_questions = res.choices[0].message.content
                    go_to('inter_practice')
                else:
                    st.error("í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨. ì´ë¯¸ì§€ PDFì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    if st.button("â¬…ï¸ ë©”ì¸ ë©”ë‰´ë¡œ", use_container_width=True):
        go_to('main_menu')

# [PAGE 4-2] ë©´ì ‘ ì‹¤ì „ ì—°ìŠµ
elif st.session_state.step == 'inter_practice':
    st.title("ğŸ™ï¸ ì‹¤ì „ ë©´ì ‘ íŠ¸ë ˆì´ë‹")
    st.info("AI ì…í•™ì‚¬ì •ê´€ì˜ ì˜ˆìƒ ì§ˆë¬¸:")
    st.write(st.session_state.uni_questions)
    
    st.markdown("---")
    target_q = st.text_input("ë‹µë³€í•  ì§ˆë¬¸ ì…ë ¥")
    audio = st.audio_input("ë‹µë³€ ë…¹ìŒ")
    
    if audio and target_q:
        with st.spinner("ë©´ì ‘ê´€ í‰ê°€ ì¤‘..."):
            audio.seek(0)
            transcript = client.audio.transcriptions.create(model="whisper-1", file=audio).text
            
            eval_prompt = f"ì§ˆë¬¸:{target_q}\në‹µë³€:{transcript}\ní‰ê°€:ë…¼ë¦¬,ì§„ì •,ìì‹ ,ì í•©. JSONì¶œë ¥."
            res = client.chat.completions.create(model="gpt-4o", messages=[{"role":"user", "content":eval_prompt}], response_format={"type":"json_object"})
            data = json.loads(res.choices[0].message.content)
            
            st.subheader("í‰ê°€ ë¦¬í¬íŠ¸")
            st.write(data.get('feedback'))
            
            cats = ['ë…¼ë¦¬', 'ì§„ì •', 'ìì‹ ', 'ì í•©']
            vals = [data.get('logic',0)*10, data.get('sincerity',0)*10, data.get('confidence',0)*10, data.get('suitability',0)*10]
            fig = go.Figure(data=go.Scatterpolar(r=vals, theta=cats, fill='toself'))
            fig.update_layout(polar=dict(radialaxis=dict(range=[0,100])), showlegend=False)
            st.plotly_chart(fig)
            
    st.markdown("---")
    if st.button("â¬…ï¸ ë‹¤ë¥¸ ìƒê¸°ë¶€ ì˜¬ë¦¬ê¸°", use_container_width=True):
        go_to('inter_upload')
