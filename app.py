import os
import random
import difflib
import numpy as np
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import PyPDF2  # PDF ì½ê¸°ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬

# ==========================================
# ğŸ”‘ ì„¤ì • ë° API í‚¤
# ==========================================
st.set_page_config(page_title="Spec-trum Uni", page_icon="ğŸ“", layout="wide")

password = st.text_input(" ì ‘ì† ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

if password != "0601": 
    st.warning("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()  

if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    pass

client = OpenAI()

# ==========================================
# ğŸ“Š ê³µí†µ ë¶„ì„ í•¨ìˆ˜ (ë°œí‘œ/ë©´ì ‘ ê³µìš©)
# ==========================================
def analyze_audio_features(y, sr):
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    non_silent_intervals = librosa.effects.split(y, top_db=20)
    non_silent_duration = sum([(end - start) for start, end in non_silent_intervals]) / sr
    total_duration = librosa.get_duration(y=y, sr=sr)
    silence_ratio = (total_duration - non_silent_duration) / total_duration
    return times, rms, cent, total_duration, silence_ratio

def extract_text_from_pdf(pdf_file):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    # ë„ˆë¬´ ê¸¸ë©´ ë¹„ìš© ë¬¸ì œ/í† í° ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ì•ë¶€ë¶„ 5í˜ì´ì§€ë§Œ ì½ê¸° (ì¡°ì ˆ ê°€ëŠ¥)
    for page in reader.pages[:5]: 
        text += page.extract_text()
    return text

# ==========================================
# ğŸ›ï¸ ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.title("ğŸ“ Spec-trum Uni")
    st.info("ëŒ€ì… ìˆ˜ì‹œ ë©´ì ‘ & ìˆ˜í–‰í‰ê°€ ë°œí‘œ")
    menu = st.radio("ê¸°ëŠ¥ ì„ íƒ", ["1. ìˆ˜í–‰í‰ê°€ ë°œí‘œ ë§ˆìŠ¤í„°", "2. ìƒê¸°ë¶€ ê¸°ë°˜ ëŒ€ì… ë©´ì ‘"])

# ==========================================
# [ê¸°ëŠ¥ 1] ë°œí‘œ All-in-One (ê¸°ì¡´ ìœ ì§€)
# ==========================================
if menu == "1. ìˆ˜í–‰í‰ê°€ ë°œí‘œ ë§ˆìŠ¤í„°":
    st.title("ğŸ¤ ìˆ˜í–‰í‰ê°€ ë°œí‘œ ë§ˆìŠ¤í„°")
    tab1, tab2, tab3 = st.tabs(["ğŸ“ ëŒ€ë³¸ ì‘ì„±", "ğŸ§ ëŒ€ë³¸ í‰ê°€", "ğŸ“Š ë°œí‘œ ëŠ¥ë ¥ í‰ê°€"])
    
    # (ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ë¯€ë¡œ, í•µì‹¬ë§Œ ìœ ì§€í•˜ê³  ìƒëµí•©ë‹ˆë‹¤. 
    #  ì‹¤ì œ ì ìš© ì‹œì—ëŠ” ì•„ê¹Œ ì‘ì„±í•´ ë“œë¦° [ê¸°ëŠ¥ 1] ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤.)
    with tab1:
        st.write("ë°œí‘œ ì£¼ì œì™€ ìƒí™©ì„ ì…ë ¥í•˜ë©´ AIê°€ ëŒ€ë³¸ì„ ì¨ì¤ë‹ˆë‹¤.")
        # ... (ì´ì „ ì½”ë“œì˜ ëŒ€ë³¸ ì‘ì„± ë¡œì§) ...
        # (ì•„ê¹Œ ì½”ë“œê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”. í•„ìš”í•˜ë©´ ë‹¤ì‹œ í•©ì³ë“œë¦½ë‹ˆë‹¤.)

# ==========================================
# [ê¸°ëŠ¥ 2] ìƒê¸°ë¶€ ê¸°ë°˜ ëŒ€ì… ë©´ì ‘ (ëŒ€í­ ìˆ˜ì •ë¨)
# ==========================================
elif menu == "2. ìƒê¸°ë¶€ ê¸°ë°˜ ëŒ€ì… ë©´ì ‘":
    st.title("ğŸ“ ìƒí™œê¸°ë¡ë¶€ ê¸°ë°˜ ë©´ì ‘ (ì…í•™ì‚¬ì •ê´€ ëª¨ë“œ)")
    st.markdown("ë‹¹ì‹ ì˜ **ìƒí™œê¸°ë¡ë¶€(PDF)**ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. AI ì…í•™ì‚¬ì •ê´€ì´ ë‚´ìš©ì„ ë¶„ì„í•´ **ë§ì¶¤í˜• ì˜ˆìƒ ì§ˆë¬¸**ì„ ë˜ì§‘ë‹ˆë‹¤.")
    
    # 2.1 ìƒê¸°ë¶€ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ğŸ“‚ ìƒí™œê¸°ë¡ë¶€ PDF ì—…ë¡œë“œ", type="pdf")
    
    if uploaded_file is not None:
        with st.spinner("ğŸ“„ ìƒê¸°ë¶€ ë‚´ìš©ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
            student_record_text = extract_text_from_pdf(uploaded_file)
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
            if len(student_record_text) < 50:
                st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¡œ ëœ PDFì¸ê°€ìš”?")
            else:
                st.success("âœ… ë¶„ì„ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
                
                # 2.2 ì§ˆë¬¸ ìƒì„± (GPT-4o í™œìš©)
                if st.button("ğŸ¤– ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±í•˜ê¸°"):
                    prompt = f"""
                    ë‹¹ì‹ ì€ ëŒ€í•™ ì…í•™ì‚¬ì •ê´€ì…ë‹ˆë‹¤.
                    ì•„ë˜ëŠ” ì§€ì›ìì˜ ìƒí™œê¸°ë¡ë¶€ ë‚´ìš© ì¼ë¶€ì…ë‹ˆë‹¤.
                    
                    [ìƒê¸°ë¶€ ë‚´ìš©]
                    {student_record_text[:3000]}  # (í† í° ì œí•œì„ ìœ„í•´ 3000ìë§Œ ì „ì†¡)
                    
                    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ì „ê³µ ì í•©ì„±, ì¸ì„±, ë°œì „ ê°€ëŠ¥ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•œ **ë‚ ì¹´ë¡œìš´ ë©´ì ‘ ì§ˆë¬¸ 3ê°€ì§€**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
                    ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ì–´ì•¼ í•˜ë©°, ìƒê¸°ë¶€ì— ìˆëŠ” íŠ¹ì • í™œë™(ë™ì•„ë¦¬, ì„¸íŠ¹ ë“±)ì„ ì–¸ê¸‰í•˜ë©° ë¬¼ì–´ë´ì•¼ í•©ë‹ˆë‹¤.
                    """
                    
                    res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": prompt}]
                    )
                    
                    # ì§ˆë¬¸ ì €ì¥
                    st.session_state['generated_questions'] = res.choices[0].message.content
    
    # 2.3 ì§ˆë¬¸ ì„ íƒ ë° ë‹µë³€ ì—°ìŠµ
    if 'generated_questions' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ§ AI ì…í•™ì‚¬ì •ê´€ì˜ ì˜ˆìƒ ì§ˆë¬¸")
        st.info(st.session_state['generated_questions'])
        
        st.markdown("---")
        st.subheader("ğŸ™ï¸ ì‹¤ì „ ë‹µë³€ ì—°ìŠµ")
        st.caption("ìœ„ ì§ˆë¬¸ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ ë‹µë³€í•´ ë³´ì„¸ìš”.")
        
        target_q = st.text_input("ë‹µë³€í•  ì§ˆë¬¸ì„ ì—¬ê¸°ì— ë³µì‚¬í•´ ë„£ìœ¼ì„¸ìš”", placeholder="ì˜ˆ: 2ë²ˆ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤.")
        
        audio_input = st.audio_input("ğŸ”´ ë…¹ìŒ ì‹œì‘")
        
        if audio_input and target_q:
            with st.spinner("ì…í•™ì‚¬ì •ê´€ì´ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                # STT
                audio_input.seek(0)
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_input).text
                
                st.markdown("### ğŸ—£ ë‚´ ë‹µë³€")
                st.write(transcript)
                
                # GPT-4o í‰ê°€
                eval_prompt = f"""
                ì§ˆë¬¸: {target_q}
                ë‹µë³€: {transcript}
                
                ì—­í• : ëŒ€í•™ ì…í•™ì‚¬ì •ê´€
                í‰ê°€ ê¸°ì¤€:
                1. êµ¬ì²´ì„± (ìì‹ ì˜ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ê·¼ê±°ë¡œ ë“¤ì—ˆëŠ”ê°€?)
                2. ì§„ì •ì„± (ìƒê¸°ë¶€ ë‚´ìš©ê³¼ ì¼ê´€ì„±ì´ ìˆëŠ”ê°€?)
                3. ë…¼ë¦¬ì„±
                
                í”¼ë“œë°±ì„ ì£¼ê³  100ì  ë§Œì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ì„¸ìš”.
                """
                res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": eval_prompt}])
                
                st.markdown("### ğŸ“ í‰ê°€ ê²°ê³¼")
                st.write(res.choices[0].message.content)
