import os
import random
import difflib
import numpy as np
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import plotly.express as px
import PyPDF2
from pdf2image import convert_from_bytes
import pytesseract

from collections import Counter
import json

# ==========================================
# ğŸ”‘ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Spec-trum Pro", page_icon="ğŸ™ï¸", layout="wide")

# 1. ì ‘ì† ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
password = st.text_input("ğŸ”’ ì ‘ì† ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if password != "0601": 
    st.warning("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    st.stop()

# 2. API í‚¤ ì„¤ì • (Streamlit Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°)
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (Secretsê°€ ì—†ì„ ë•Œ ëŒ€ë¹„)
    pass

client = OpenAI()

# ==========================================
# ğŸ“Š ë¶„ì„ í•¨ìˆ˜ ëª¨ìŒ (ì—”ì§„)
# ==========================================
def analyze_audio_features(y, sr):
    """ì˜¤ë””ì˜¤ì˜ ë¬¼ë¦¬ì  íŠ¹ì§• ì¶”ì¶œ (ì†ë„, ì¹¨ë¬µ, í†¤, í¬ê¸° ë“±)"""
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    
    # ì¹¨ë¬µ êµ¬ê°„ ê³„ì‚° (25dB ê¸°ì¤€)
    non_silent_intervals = librosa.effects.split(y, top_db=25)
    non_silent_duration = sum([(end - start) for start, end in non_silent_intervals]) / sr
    total_duration = librosa.get_duration(y=y, sr=sr)
    
    # ì²« ë°œí™”ê¹Œì§€ ê±¸ë¦° ì‹œê°„ (Initial Delay) - ë©´ì ‘ ê¸´ì¥ë„ ì¸¡ì •ìš©
    if len(non_silent_intervals) > 0:
        initial_silence = librosa.frames_to_time(non_silent_intervals[0][0], sr=sr)
    else:
        initial_silence = 0
    
    silence_duration = total_duration - non_silent_duration
    silence_ratio = silence_duration / total_duration if total_duration > 0 else 0
    
    return times, rms, cent, total_duration, non_silent_duration, silence_duration, silence_ratio, initial_silence

def analyze_text_patterns(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ìŠµê´€ì–´(Filler)ì™€ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„"""
    # ìŠµê´€ì–´ ë¶„ì„
    fillers = ["ìŒ", "ì–´", "ê·¸", "ë§‰", "ì´ì œ", "ì•½ê°„", "ì €", "ì‚¬ì‹¤"]
    filler_counts = {f: text.count(f) for f in fillers if text.count(f) > 0}
    total_fillers = sum(filler_counts.values())
    
    # í‚¤ì›Œë“œ ë¶„ì„ (ê°„ë‹¨í•œ ë¹ˆë„ìˆ˜)
    words = text.replace(".", "").split()
    valid_words = [w for w in words if len(w) >= 2 and w not in fillers]
    top_keywords = Counter(valid_words).most_common(5)
    
    return filler_counts, total_fillers, top_keywords

def extract_text_from_pdf(pdf_file):
    """PDF ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    # í˜ì´ì§€ ì œí•œ ì—†ì´ ì „ì²´ ì½ê¸° (ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ìš”ì•½ ëª¨ë¸ì€ mini ì‚¬ìš© ê¶Œì¥)
    for page in reader.pages: 
        extracted = page.extract_text()
        if extracted:
            text += extracted + "\n"
    return text

def calculate_similarity(text1, text2):
    """ëŒ€ë³¸ ì¼ì¹˜ë„(ì •í™•ì„±) ê³„ì‚°"""
    matcher = difflib.SequenceMatcher(None, text1, text2)
    return matcher.ratio() * 100

# ==========================================
# ğŸ›ï¸ ë©”ì¸ UI & ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.title("SPEC-TRUM")
    st.caption("ì—­ëŸ‰ ì „ë‹¬ì˜ ìŠ¤í™íŠ¸ëŸ¼ì„ ë„“íˆë‹¤")
    st.markdown("---")
    menu = st.radio("ê¸°ëŠ¥ ì„ íƒ", ["1. ë°œí‘œ ì¤€ë¹„ ", "2. ìƒê¸°ë¶€ ì‹¬ì¸µ ë©´ì ‘"])
    st.markdown("---")

# ==========================================
# [ê¸°ëŠ¥ 1] ë°œí‘œ ì¤€ë¹„
# ==========================================
if menu == "1. ë°œí‘œ ì¤€ë¹„":
    st.title("ğŸ¤ ë°œí‘œ ì¤€ë¹„")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ 1.1 ëŒ€ë³¸ ì‘ì„±", "ğŸ§ 1.2 ëŒ€ë³¸ í‰ê°€", "ğŸ“Š 1.3 ë°œí‘œ ëŠ¥ë ¥ í‰ê°€"])
    
    # --- [1.1 ëŒ€ë³¸ ì‘ì„±] ---
    with tab1:
        st.header("AIê°€ ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤.")
        col1, col2 = st.columns(2)
        with col1:
            p_topic = st.text_input("ë°œí‘œ ì£¼ì œ, ì£¼ì¥", placeholder="ì˜ˆ: ìƒì„±í˜• AIì˜ êµìœ¡ì  í™œìš©")
            p_context = st.text_input("ë°œí‘œ ìƒí™©", placeholder="ì˜ˆ: í”„ë¡œê·¸ë˜ë° ë°œí‘œ ìˆ˜í–‰í‰ê°€")
        with col2:
            p_requirements = st.text_area("ìš”êµ¬ì‚¬í•­", placeholder="3ë¶„ ë°œí‘œ, ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°")
            
        if st.button("âœ¨ ëŒ€ë³¸ ìƒì„±í•˜ê¸° "):
            if not p_topic:
                st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë°œí‘œëŒ€ë³¸ì„ ì‘ì„±ì¤‘ì…ë‹ˆë‹¤..."):
                    prompt = f"ì£¼ì œ: {p_topic}\nìƒí™©: {p_context}\nìš”êµ¬ì‚¬í•­: {p_requirements}\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ì¤˜."
                    res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
                    st.session_state['script'] = res.choices[0].message.content
                    st.success("ëŒ€ë³¸ ìƒì„± ì™„ë£Œ!")

        if 'script' in st.session_state:
            st.text_area("ìƒì„±ëœ ëŒ€ë³¸", st.session_state['script'], height=300)

    # --- [1.2 ëŒ€ë³¸ í‰ê°€] ---
    with tab2:
        st.header("ì‘ì„±í•œ ëŒ€ë³¸ í”¼ë“œë°±")
        user_script = st.text_area("í‰ê°€ë°›ì„ ëŒ€ë³¸ ì…ë ¥", value=st.session_state.get('script', ""), height=200)
        user_intent = st.text_input("ì˜ë„í•˜ê³ ì í•˜ëŠ” ë°”", placeholder="ì˜ˆ: ë‚˜ì˜ ë¹„íŒì  ì‚¬ê³ ë ¥ì„ ê°•ì¡°")
        
        if st.button("ğŸ§ í”¼ë“œë°± ë°›ê¸°"):
            if user_script:
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    prompt = f"ëŒ€ë³¸: {user_script}\nì˜ë„: {user_intent}\nì´ ëŒ€ë³¸ì„ í‰ê°€í•˜ê³  ìˆ˜ì •í•  ì  3ê°€ì§€ë¥¼ ì•Œë ¤ì¤˜."
                    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                    st.info(res.choices[0].message.content)

    # --- [1.3 ë°œí‘œ ëŠ¥ë ¥ í‰ê°€] ---
    with tab3:
        st.header("ğŸ“Š ì‹¤ì „ ë°œí‘œ ëŠ¥ë ¥ ì‹¬ì¸µ ë¶„ì„")
        st.caption("ëŒ€ë³¸ê³¼ ì‹¤ì œ ëª©ì†Œë¦¬ë¥¼ ë¹„êµí•˜ì—¬ ì •ë°€ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        ref_text = st.text_area("ëŒ€ë³¸: ", value=st.session_state.get('script', ""), height=100)
        audio_input = st.audio_input("ğŸ”´ ë°œí‘œ ë…¹ìŒ ì‹œì‘")
        
        if audio_input and ref_text:
            with st.spinner("6-Point ì •ë°€ ë¶„ì„ ì¤‘..."):
                # 1. ì˜¤ë””ì˜¤ ë¶„ì„
                y, sr = librosa.load(audio_input, sr=None)
                times, rms, cent, total_dur, _, silent_dur, silence_ratio, _ = analyze_audio_features(y, sr)
                tempo_arr, _ = librosa.beat.beat_track(y=y, sr=sr)
                tempo = float(tempo_arr)
                
                # 2. STT
                audio_input.seek(0)
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_input).text
                
                # 3. í…ìŠ¤íŠ¸ ë¶„ì„ (ì •í™•ë„, ìŠµê´€ì–´)
                accuracy = calculate_similarity(ref_text, transcript)
                filler_counts, total_fillers, top_keywords = analyze_text_patterns(transcript)
                
                # === ë¦¬í¬íŠ¸ ì¶œë ¥ ===
                st.markdown("---")
                # ì„¹ì…˜ 1: í•µì‹¬ ì§€í‘œ
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("ì†ë„ (BPM)", f"{tempo:.0f}", delta="ê¶Œì¥ 110~130")
                c2.metric("ë°œìŒ ì •í™•ë„", f"{accuracy:.1f}%", delta="ëª©í‘œ 90%")
                c3.metric("ìŠµê´€ì–´(ìŒ/ì–´)", f"{total_fillers}íšŒ", delta_color="inverse")
                c4.metric("ë°œí‘œ ì‹œê°„", f"{total_dur:.1f}ì´ˆ")
                
                st.markdown("---")
                # ì„¹ì…˜ 2: ê·¸ë˜í”„
                g1, g2 = st.columns(2)
                with g1:
                    st.subheader("ğŸ“ˆ ë‹¤ì´ë‚´ë¯¹ìŠ¤ (í†¤ & í¬ê¸°)")
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(x=times, y=rms, name='ì„±ëŸ‰(Volume)', fill='tozeroy', line=dict(color='#EF4444')))
                    norm_cent = (cent - np.min(cent)) / (np.max(cent) - np.min(cent)) * np.max(rms)
                    fig.add_trace(go.Scatter(x=times, y=norm_cent, name='í†¤(Tone)', line=dict(color='#10B981'), opacity=0.5))
                    fig.update_layout(height=300, margin=dict(l=0,r=0,t=0,b=0))
                    st.plotly_chart(fig, use_container_width=True)
                
                with g2:
                    st.subheader("ğŸ—£ï¸ ë°œí™” ì ìœ ìœ¨")
                    fig_pie = px.pie(values=[total_dur-silent_dur, silent_dur], names=["ë§í•œ ì‹œê°„", "ì¹¨ë¬µ"], 
                                     color_discrete_sequence=['#3B82F6', '#E5E7EB'], hole=0.4)
                    fig_pie.update_layout(height=300, margin=dict(l=0,r=0,t=0,b=0))
                    st.plotly_chart(fig_pie, use_container_width=True)

                # ì„¹ì…˜ 3: í‚¤ì›Œë“œ & ìŠµê´€ì–´
                st.markdown("#### ğŸ”‘ í‚¤ì›Œë“œ & ìŠµê´€ì–´ ë¶„ì„")
                k1, k2 = st.columns(2)
                with k1:
                    st.write("**ë§ì´ ì“´ ë‹¨ì–´ Top 5**")
                    st.write(top_keywords)
                with k2:
                    st.write("**ê°ì§€ëœ ìŠµê´€ì–´**")
                    st.write(filler_counts if filler_counts else "ì—†ìŒ (ì™„ë²½í•©ë‹ˆë‹¤!)")
                
                with st.expander("ë‚´ìš© ë³´ê¸° (STT)"):
                    st.write(transcript)

# ==========================================
# [ê¸°ëŠ¥ 2] ìƒê¸°ë¶€ ì‹¬ì¸µ ë©´ì ‘ 
# ==========================================
elif menu == "2. ìƒê¸°ë¶€ ì‹¬ì¸µ ë©´ì ‘":
    st.title("ğŸ“ ìƒí™œê¸°ë¡ë¶€ ê¸°ë°˜ ë©´ì ‘ (ì…í•™ì‚¬ì •ê´€)")
    st.markdown("ìƒê¸°ë¶€(PDF)ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ì „ì²´ë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤.")
    
    # 2.1 íŒŒì¼ ì—…ë¡œë“œ ë° ì§ˆë¬¸ ìƒì„±
    uploaded_file = st.file_uploader("ìƒí™œê¸°ë¡ë¶€ PDF ì—…ë¡œë“œ", type="pdf")
    
    if uploaded_file:
        with st.spinner("ìƒê¸°ë¶€ ì „ì²´ë¥¼ ì½ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (Mini ëª¨ë¸ë¡œ ë¹„ìš© ì ˆê°)"):
            text = extract_text_from_pdf(uploaded_file)
            
            if len(text) > 50:
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! (ì´ {len(text)}ì ì½ìŒ)")
                
                if st.button("ğŸ¤– ë§ì¶¤í˜• ì§ˆë¬¸ ì¶”ì¶œí•˜ê¸°"):
                    # ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ: ê¸´ í…ìŠ¤íŠ¸ ë¶„ì„ì€ gpt-4o-mini ì‚¬ìš© (ë¹„ìš© 1/20)
                    prompt = f"""
                    ë‹¹ì‹ ì€ ì…í•™ì‚¬ì •ê´€ì…ë‹ˆë‹¤.
                    [ìƒê¸°ë¶€ ë‚´ìš© ì „ì²´]
                    {text}

                    
                    ì§€ì›ìì˜ ì „ê³µ ì í•©ì„±ê³¼ ì¸ì„±ì„ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ë‚ ì¹´ë¡œìš´ ë©´ì ‘ ì§ˆë¬¸ 3ê°€ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
                    ìƒê¸°ë¶€ ë‚´ì˜ êµ¬ì²´ì ì¸ í™œë™(ë™ì•„ë¦¬, ì„¸íŠ¹, ë…ì„œ ë“±)ì„ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
                    """
                    res = client.chat.completions.create(
                        model="gpt-4o-mini", # ğŸ‘ˆ Mini ëª¨ë¸ ì‚¬ìš©!
                        messages=[{"role": "user", "content": prompt}]
                    )
                    st.session_state['uni_questions'] = res.choices[0].message.content
            else:
                st.error("í…ìŠ¤íŠ¸ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì•”í˜¸ ê±¸ë¦° PDFì¸ì§€ í™•ì¸í•˜ì„¸ìš”)")

    # 2.2 ì§ˆë¬¸ í™•ì¸ ë° ë‹µë³€
    if 'uni_questions' in st.session_state:
        st.info(st.session_state['uni_questions'])
        target_q = st.text_input("ë‹µë³€í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ìœ„ ì§ˆë¬¸ ì¤‘ í•˜ë‚˜ë¥¼ ë³µì‚¬í•˜ì„¸ìš”.")

        audio_input = st.audio_input("ğŸ”´ ë‹µë³€ ë…¹ìŒ ì‹œì‘")
        
        if audio_input and target_q:
            with st.spinner("ë©´ì ‘ê´€ì´ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤... (í‰ê°€ëŠ” 4o ì‚¬ìš©)"):
                # 1. ì˜¤ë””ì˜¤ ë¶„ì„
                y, sr = librosa.load(audio_input, sr=None)
                _, _, _, total_dur, _, _, _, initial_silence = analyze_audio_features(y, sr)
                tempo_arr, _ = librosa.beat.beat_track(y=y, sr=sr)
                tempo = float(tempo_arr)
                
                # 2. STT
                audio_input.seek(0)
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_input).text
                filler_counts, total_fillers, _ = analyze_text_patterns(transcript)
                
                # 3. GPT-4o ì‹¬ì¸µ í‰ê°€ (JSON ì¶œë ¥)
                # ğŸ’¡ í‰ê°€ëŠ” ì§§ì€ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ì •í™•í•œ gpt-4o ì‚¬ìš©
                eval_prompt = f"""
                ì—­í• : ëƒ‰ì² í•œ ì…í•™ì‚¬ì •ê´€
                ì§ˆë¬¸: {target_q}
                ë‹µë³€: {transcript}
                
                í‰ê°€ í•­ëª©(10ì  ë§Œì ): logic(ë…¼ë¦¬ì„±), sincerity(ì§„ì •ì„±/êµ¬ì²´ì„±), confidence(íƒœë„), suitability(ì „ê³µì í•©ì„±)
                í”¼ë“œë°±ë„ í¬í•¨í•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥.
                """
                res = client.chat.completions.create(
                    model="gpt-4o", # ğŸ‘ˆ í‰ê°€ëŠ” 4o ì‚¬ìš©!
                    messages=[{"role": "user", "content": eval_prompt}],
                    response_format={"type": "json_object"}
                )
                eval_data = json.loads(res.choices[0].message.content)
                
                # === ê²°ê³¼ ë¦¬í¬íŠ¸ ===
                st.markdown("---")
                
                # ì„¹ì…˜ 1: ë©´ì ‘ ì§€í‘œ
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("ì²« ë°˜ì‘ ì†ë„", f"{initial_silence:.1f}ì´ˆ", delta="3ì´ˆ ì´ë‚´ ê¶Œì¥", delta_color="inverse")
                m2.metric("ìŠµê´€ì–´", f"{total_fillers}íšŒ", delta_color="inverse")
                m3.metric("ë§í•˜ê¸° ì†ë„", f"{tempo:.0f} BPM")
                m4.metric("ë‹µë³€ ì‹œê°„", f"{total_dur:.1f}ì´ˆ")
                
                # ì„¹ì…˜ 2: ë ˆì´ë” ì°¨íŠ¸
                st.subheader("ğŸ•¸ï¸ ì—­ëŸ‰ í‰ê°€ ë ˆì´ë”")
                categories = ['ë…¼ë¦¬ì„±', 'ì§„ì •ì„±', 'ìì‹ ê°', 'ì í•©ì„±']
                scores = [eval_data.get('logic', 0)*10, eval_data.get('sincerity', 0)*10, eval_data.get('confidence', 0)*10, eval_data.get('suitability', 0)*10]
                
                fig = go.Figure(data=go.Scatterpolar(r=scores, theta=categories, fill='toself', line_color='#4F46E5'))
                fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=False, height=350)
                st.plotly_chart(fig, use_container_width=True)
                
                # ì„¹ì…˜ 3: í”¼ë“œë°±
                st.subheader("ğŸ§‘â€ğŸ’¼ ì…í•™ì‚¬ì •ê´€ ìƒì„¸ í”¼ë“œë°±")
                st.info(eval_data.get('feedback', 'í”¼ë“œë°±ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'))
