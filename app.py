import os
import random
import difflib
import numpy as np
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import PyPDF2  # PDF ì½ê¸°ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬

# ==========================================
# ğŸ”‘ ê¸°ë³¸ ì„¤ì • ë° ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ
# ==========================================
st.set_page_config(page_title="Spec-trum Uni", page_icon="ğŸ“", layout="wide")

# 1. ì•± ì ‘ì† ë¹„ë°€ë²ˆí˜¸ (ê°„ë‹¨ ì ê¸ˆ)
password = st.text_input("ğŸ”’ ì ‘ì† ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if password != "0601": 
    st.warning("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()  # ë¹„ë°€ë²ˆí˜¸ í‹€ë¦¬ë©´ ì—¬ê¸°ì„œ ë©ˆì¶¤

# 2. OpenAI API í‚¤ ì„¤ì • (Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜)
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë“±ì„ ìœ„í•´ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì— í‚¤ ì§ì ‘ ì…ë ¥ (ë°°í¬ ì‹œì—” ì‚­ì œ ê¶Œì¥)
    pass

client = OpenAI()

# ==========================================
# ğŸ“Š ë¶„ì„ í•¨ìˆ˜ ëª¨ìŒ
# ==========================================

def calculate_similarity(text1, text2):
    """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„(ë°œìŒ ì •í™•ì„± ì§€í‘œ) ê³„ì‚°"""
    matcher = difflib.SequenceMatcher(None, text1, text2)
    return matcher.ratio() * 100

def analyze_audio_features(y, sr):
    """ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ (í¬ê¸°, í†¤, ì¹¨ë¬µ ë“±)"""
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    
    # í†¤ ë†’ë‚®ì´ (Spectral Centroid í™œìš©)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    
    # ì¹¨ë¬µ êµ¬ê°„ ê³„ì‚°
    non_silent_intervals = librosa.effects.split(y, top_db=20)
    non_silent_duration = sum([(end - start) for start, end in non_silent_intervals]) / sr
    total_duration = librosa.get_duration(y=y, sr=sr)
    
    if total_duration > 0:
        silence_ratio = (total_duration - non_silent_duration) / total_duration
    else:
        silence_ratio = 0
        
    return times, rms, cent, total_duration, silence_ratio

def extract_text_from_pdf(pdf_file):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    # ë„ˆë¬´ ê¸¸ë©´ í† í° ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ì•ë¶€ë¶„ 5í˜ì´ì§€ë§Œ ì½ê¸°
    for page in reader.pages[:5]: 
        text += page.extract_text()
    return text

# ==========================================
# ğŸ›ï¸ ì‚¬ì´ë“œë°” ë©”ë‰´
# ==========================================
with st.sidebar:
    st.title("ğŸ“ Spec-trum Uni")
    st.info("í•™ìƒë“¤ì„ ìœ„í•œ ë°œí‘œ & ë©´ì ‘ ì½”ì¹˜")
    menu = st.radio("ê¸°ëŠ¥ ì„ íƒ", ["1. ë°œí‘œ All-in-One", "2. ìƒê¸°ë¶€ ê¸°ë°˜ ëŒ€ì… ë©´ì ‘"])

# ==========================================
# [ê¸°ëŠ¥ 1] ë°œí‘œ All-in-One
# ==========================================
if menu == "1. ë°œí‘œ All-in-One":
    st.title("ğŸ¤ ìˆ˜í–‰í‰ê°€ ë°œí‘œ ë§ˆìŠ¤í„°")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ 1.1 ëŒ€ë³¸ ì‘ì„±", "ğŸ§ 1.2 ëŒ€ë³¸ í‰ê°€", "ğŸ“Š 1.3 ë°œí‘œ ëŠ¥ë ¥ í‰ê°€"])
    
    # --- [1.1 ëŒ€ë³¸ ì‘ì„±] ---
    with tab1:
        st.header("AIê°€ ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤.")
        col1, col2 = st.columns(2)
        with col1:
            p_topic = st.text_input("ë°œí‘œ ì£¼ì œ", placeholder="ì˜ˆ: ìƒì„±í˜• AIì˜ êµìœ¡ì  í™œìš©")
            p_context = st.text_input("ë°œí‘œ ìƒí™©", placeholder="ì˜ˆ: ì •ë³´ êµê³¼ ìˆ˜í–‰í‰ê°€")
        with col2:
            p_requirements = st.text_area("ìš”êµ¬ì‚¬í•­", placeholder="3ë¶„ ë°œí‘œ, ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°")
            
        if st.button("âœ¨ ëŒ€ë³¸ ìƒì„±í•˜ê¸°"):
            if not p_topic:
                st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("GPT-4o-miniê°€ ëŒ€ë³¸ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    prompt = f"ì£¼ì œ: {p_topic}\nìƒí™©: {p_context}\nìš”êµ¬ì‚¬í•­: {p_requirements}\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ì¤˜."
                    res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
                    st.session_state['script'] = res.choices[0].message.content
                    st.success("ëŒ€ë³¸ ìƒì„± ì™„ë£Œ!")

        if 'script' in st.session_state:
            st.text_area("ìƒì„±ëœ ëŒ€ë³¸", st.session_state['script'], height=300)

    # --- [1.2 ëŒ€ë³¸ í‰ê°€] ---
    with tab2:
        st.header("ì‘ì„±í•œ ëŒ€ë³¸ í”¼ë“œë°±")
        user_script = st.text_area("í‰ê°€ë°›ì„ ëŒ€ë³¸ ì…ë ¥", value=st.session_state.get('script', ""), height=200)
        user_intent = st.text_input("ì˜ë„í•˜ê³ ì í•˜ëŠ” ë°”", placeholder="ì˜ˆ: ë‚˜ì˜ ë¹„íŒì  ì‚¬ê³ ë ¥ì„ ê°•ì¡°")
        
        if st.button("ğŸ§ í”¼ë“œë°± ë°›ê¸°"):
            if user_script:
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    prompt = f"ëŒ€ë³¸: {user_script}\nì˜ë„: {user_intent}\nì´ ëŒ€ë³¸ì„ í‰ê°€í•˜ê³  ìˆ˜ì •í•  ì  3ê°€ì§€ë¥¼ ì•Œë ¤ì¤˜."
                    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                    st.info(res.choices[0].message.content)

    # --- [1.3 ë°œí‘œ ëŠ¥ë ¥ í‰ê°€] ---
    with tab3:
        st.header("ğŸ“Š ì‹¤ì „ ë°œí‘œ ëŠ¥ë ¥ ì‹¬ì¸µ ë¶„ì„")
        ref_text = st.text_area("ê¸°ì¤€ ëŒ€ë³¸ (ë°œìŒ ì •í™•ë„ ì¸¡ì •ìš©)", value=st.session_state.get('script', ""), height=100)
        audio_input = st.audio_input("ğŸ”´ ë…¹ìŒ ì‹œì‘")
        
        if audio_input and ref_text:
            with st.spinner("ì •ë°€ ë¶„ì„ ì¤‘..."):
                # 1. ì˜¤ë””ì˜¤ ë¶„ì„
                y, sr = librosa.load(audio_input, sr=None)
                times, rms, cent, duration, silence_ratio = analyze_audio_features(y, sr)
                tempo_arr, _ = librosa.beat.beat_track(y=y, sr=sr)
                tempo = float(tempo_arr)
                
                # 2. STT
                audio_input.seek(0)
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_input).text
                
                # 3. ì •í™•ë„
                accuracy = calculate_similarity(ref_text, transcript)
                
                # ê²°ê³¼ í‘œì‹œ
                st.markdown("---")
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("ì†ë„ (BPM)", f"{tempo:.0f}")
                c2.metric("ë²„ë²…ì„ ë¹„ìœ¨", f"{silence_ratio*100:.1f}%")
                c3.metric("ë°œìŒ ì •í™•ë„", f"{accuracy:.1f}%")
                c4.metric("ì‹œê°„", f"{duration:.1f}ì´ˆ")
                
                # ê·¸ë˜í”„
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=times, y=rms, name='ëª©ì†Œë¦¬ í¬ê¸°', fill='tozeroy', line=dict(color='firebrick')))
                norm_cent = (cent - np.min(cent)) / (np.max(cent) - np.min(cent)) * np.max(rms)
                fig.add_trace(go.Scatter(x=times, y=norm_cent, name='í†¤ ë†’ë‚®ì´', line=dict(color='royalblue'), opacity=0.5))
                fig.update_layout(title="ëª©ì†Œë¦¬ ë³€í™” ë¶„ì„", height=300)
                st.plotly_chart(fig, use_container_width=True)

# ==========================================
# [ê¸°ëŠ¥ 2] ìƒê¸°ë¶€ ê¸°ë°˜ ëŒ€ì… ë©´ì ‘
# ==========================================
elif menu == "2. ìƒê¸°ë¶€ ê¸°ë°˜ ëŒ€ì… ë©´ì ‘":
    st.title("ğŸ“ ìƒí™œê¸°ë¡ë¶€ ê¸°ë°˜ ë©´ì ‘ (ì…í•™ì‚¬ì •ê´€ ëª¨ë“œ)")
    st.markdown("ìƒê¸°ë¶€(PDF)ë¥¼ ì—…ë¡œë“œí•˜ë©´ AI ì…í•™ì‚¬ì •ê´€ì´ **ë§ì¶¤í˜• ì§ˆë¬¸**ì„ ë˜ì§‘ë‹ˆë‹¤.")
    
    uploaded_file = st.file_uploader("ğŸ“‚ ìƒí™œê¸°ë¡ë¶€ PDF ì—…ë¡œë“œ", type="pdf")
    
    if uploaded_file is not None:
        with st.spinner("ìƒê¸°ë¶€ ë¶„ì„ ì¤‘..."):
            text = extract_text_from_pdf(uploaded_file)
            if len(text) < 50:
                st.error("í…ìŠ¤íŠ¸ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                if st.button("ğŸ¤– ë©´ì ‘ ì§ˆë¬¸ ìƒì„±í•˜ê¸°"):
                    prompt = f"ë‹¹ì‹ ì€ ì…í•™ì‚¬ì •ê´€ì…ë‹ˆë‹¤.\n[ìƒê¸°ë¶€ ë‚´ìš©]\n{text[:3000]}\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‚ ì¹´ë¡œìš´ ë©´ì ‘ ì§ˆë¬¸ 3ê°€ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”."
                    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                    st.session_state['generated_questions'] = res.choices[0].message.content

    if 'generated_questions' in st.session_state:
        st.markdown("---")
        st.info(st.session_state['generated_questions'])
        
        target_q = st.text_input("ë‹µë³€í•  ì§ˆë¬¸ì„ ë³µì‚¬í•´ ë„£ìœ¼ì„¸ìš”")
        audio_input = st.audio_input("ğŸ”´ ë‹µë³€ ë…¹ìŒ")
        
        if audio_input and target_q:
            with st.spinner("í‰ê°€ ì¤‘..."):
                audio_input.seek(0)
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_input).text
                
                st.write(f"ğŸ—£ ë‹µë³€: {transcript}")
                
                eval_prompt = f"ì§ˆë¬¸: {target_q}\në‹µë³€: {transcript}\nì—­í• : ì…í•™ì‚¬ì •ê´€\ní‰ê°€: êµ¬ì²´ì„±, ì§„ì •ì„±, ë…¼ë¦¬ì„± ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ì™€ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”."
                res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": eval_prompt}])
                st.write(res.choices[0].message.content)
