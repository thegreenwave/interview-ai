import os
import random
import difflib
import numpy as np
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import plotly.express as px
import PyPDF2
from collections import Counter
import json

# ==========================================
# ğŸ”‘ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Spec-trum Pro", page_icon="ğŸ“", layout="wide")

password = st.text_input("ğŸ”’ ì ‘ì† ë¹„ë°€ë²ˆí˜¸", type="password")
if password != "0601": # ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
    st.warning("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    pass

client = OpenAI()

# ==========================================
# ğŸ“Š ë¶„ì„ í•¨ìˆ˜ ëª¨ìŒ
# ==========================================
def analyze_audio_features(y, sr):
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    
    # ì¹¨ë¬µ êµ¬ê°„ ê³„ì‚° (25dB ê¸°ì¤€)
    non_silent_intervals = librosa.effects.split(y, top_db=25)
    non_silent_duration = sum([(end - start) for start, end in non_silent_intervals]) / sr
    total_duration = librosa.get_duration(y=y, sr=sr)
    
    # ì²« ë°œí™”ê¹Œì§€ ê±¸ë¦° ì‹œê°„ (Initial Delay) - ë©´ì ‘ì—ì„œ ì¤‘ìš”!
    if len(non_silent_intervals) > 0:
        initial_silence = librosa.frames_to_time(non_silent_intervals[0][0], sr=sr)
    else:
        initial_silence = 0
    
    silence_duration = total_duration - non_silent_duration
    silence_ratio = silence_duration / total_duration if total_duration > 0 else 0
    
    return times, rms, cent, total_duration, non_silent_duration, silence_duration, silence_ratio, initial_silence

def analyze_text_patterns(text):
    fillers = ["ìŒ", "ì–´", "ê·¸", "ë§‰", "ì´ì œ", "ì•½ê°„", "ì €"]
    filler_counts = {f: text.count(f) for f in fillers if text.count(f) > 0}
    total_fillers = sum(filler_counts.values())
    return filler_counts, total_fillers

def extract_text_from_pdf(pdf_file):
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in reader.pages[:5]: 
        text += page.extract_text()
    return text

# ==========================================
# ğŸ›ï¸ ë©”ì¸ í™”ë©´ êµ¬ì„±
# ==========================================
with st.sidebar:
    st.title("SPEC-TRUM")
    st.caption("ì—­ëŸ‰ì˜ ìŠ¤í™íŠ¸ëŸ¼ì„ ë„“íˆë‹¤")
    menu = st.radio("Mode", ["1. ë°œí‘œ ë§ˆìŠ¤í„° (All-in-One)", "2. ìƒê¸°ë¶€ ì‹¬ì¸µ ë©´ì ‘"])

# ==========================================
# [ê¸°ëŠ¥ 1] ë°œí‘œ ë§ˆìŠ¤í„° (ê¸°ì¡´ ìœ ì§€ - ìš”ì•½ë¨)
# ==========================================
if menu == "1. ë°œí‘œ ë§ˆìŠ¤í„° (All-in-One)":
    st.title("ğŸ¤ ìˆ˜í–‰í‰ê°€ ë°œí‘œ ë§ˆìŠ¤í„°")
    tab1, tab2 = st.tabs(["ğŸ“ ëŒ€ë³¸ ì‘ì„±", "ğŸ“Š ë°œí‘œ ì—°ìŠµ"])
    
    with tab1:
        st.write("ë°œí‘œ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ëŒ€ë³¸ì„ ì¨ì¤ë‹ˆë‹¤.")
        topic = st.text_input("ì£¼ì œ")
        if st.button("ëŒ€ë³¸ ìƒì„±"):
            res = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role":"user", "content":f"{topic} ë°œí‘œ ëŒ€ë³¸ 3ë¶„ ë¶„ëŸ‰ ì¨ì¤˜"}])
            st.session_state['script'] = res.choices[0].message.content
            st.success("ì™„ë£Œ!")
        if 'script' in st.session_state:
            st.text_area("ëŒ€ë³¸", st.session_state['script'])
            
    with tab2:
        st.write("ëŒ€ë³¸ì„ ë³´ê³  ì—°ìŠµí•˜ì„¸ìš”.")
        st.audio_input("ë°œí‘œ ë…¹ìŒ (ê¸°ëŠ¥ 1ì€ ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ)")

# ==========================================
# [ê¸°ëŠ¥ 2] ìƒê¸°ë¶€ ì‹¬ì¸µ ë©´ì ‘ (ëŒ€ê·œëª¨ ì—…ë°ì´íŠ¸)
# ==========================================
elif menu == "2. ìƒê¸°ë¶€ ì‹¬ì¸µ ë©´ì ‘":
    st.title("ğŸ“ ìƒí™œê¸°ë¡ë¶€ ê¸°ë°˜ ë©´ì ‘ (ì…í•™ì‚¬ì •ê´€ ëª¨ë“œ)")
    st.markdown("ìƒê¸°ë¶€ PDFë¥¼ ë¶„ì„í•˜ì—¬ **ë‚˜ë§Œì„ ìœ„í•œ ì†¡ê³³ ì§ˆë¬¸**ì„ ë˜ì§€ê³ , ë‹µë³€ íƒœë„ì™€ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # 2.1 íŒŒì¼ ì—…ë¡œë“œ ë° ì§ˆë¬¸ ìƒì„±
    with st.expander("ğŸ“‚ 1ë‹¨ê³„: ìƒê¸°ë¶€ ì—…ë¡œë“œ ë° ì§ˆë¬¸ ìƒì„±", expanded=True):
        uploaded_file = st.file_uploader("ìƒí™œê¸°ë¡ë¶€ PDF ì—…ë¡œë“œ", type="pdf")
        
        if uploaded_file:
            text = extract_text_from_pdf(uploaded_file)
            if len(text) > 50:
                st.success("ìƒê¸°ë¶€ ë¶„ì„ ì™„ë£Œ!")
                if st.button("ğŸ¤– ë§ì¶¤í˜• ì§ˆë¬¸ ì¶”ì¶œí•˜ê¸°"):
                    with st.spinner("ì…í•™ì‚¬ì •ê´€ì´ ìƒê¸°ë¶€ë¥¼ ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."):
                        prompt = f"""
                        ë‹¹ì‹ ì€ ì…í•™ì‚¬ì •ê´€ì…ë‹ˆë‹¤.
                        [ìƒê¸°ë¶€ ë‚´ìš©]
                        {text[:3000]}
                        
                        ì§€ì›ìì˜ ì „ê³µ ì í•©ì„±ê³¼ ì¸ì„±ì„ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ë‚ ì¹´ë¡œìš´ ë©´ì ‘ ì§ˆë¬¸ 3ê°€ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
                        ì¶œë ¥ í˜•ì‹:
                        1. [í™œë™ëª…] ì§ˆë¬¸ ë‚´ìš©
                        2. [í™œë™ëª…] ì§ˆë¬¸ ë‚´ìš©
                        3. [í™œë™ëª…] ì§ˆë¬¸ ë‚´ìš©
                        """
                        res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                        st.session_state['uni_questions'] = res.choices[0].message.content
            else:
                st.error("í…ìŠ¤íŠ¸ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2.2 ì§ˆë¬¸ í™•ì¸ ë° ì„ íƒ
    if 'uni_questions' in st.session_state:
        st.info(st.session_state['uni_questions'])
        target_q = st.text_input("ì—°ìŠµí•  ì§ˆë¬¸ì„ ì—¬ê¸°ì— ë³µì‚¬í•´ ë„£ìœ¼ì„¸ìš”", placeholder="ìœ„ ì§ˆë¬¸ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ ì…ë ¥í•˜ì„¸ìš”.")

        st.markdown("---")
        st.subheader("ğŸ™ï¸ 2ë‹¨ê³„: ì‹¤ì „ ë‹µë³€ & ì •ë°€ ë¶„ì„")
        st.caption("ë©´ì ‘ê´€ì˜ ëˆˆì„ ë³´ê³  ë§í•˜ë“¯ì´ ë…¹ìŒí•˜ì„¸ìš”.")
        
        audio_input = st.audio_input("ğŸ”´ ë‹µë³€ ë…¹ìŒ ì‹œì‘")
        
        if audio_input and target_q:
            with st.spinner("ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # 1. ì˜¤ë””ì˜¤ ë¶„ì„
                y, sr = librosa.load(audio_input, sr=None)
                times, rms, cent, total_dur, _, silent_dur, silence_ratio, initial_silence = analyze_audio_features(y, sr)
                
                tempo_arr, _ = librosa.beat.beat_track(y=y, sr=sr)
                tempo = float(tempo_arr)
                
                # 2. STT ë° í…ìŠ¤íŠ¸ ë¶„ì„
                audio_input.seek(0)
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_input).text
                filler_counts, total_fillers = analyze_text_patterns(transcript)
                
                # 3. GPT-4o ì‹¬ì¸µ í‰ê°€ (JSON ì¶œë ¥ ìš”ì²­)
                eval_prompt = f"""
                ì—­í• : ëƒ‰ì² í•œ ì…í•™ì‚¬ì •ê´€
                ì§ˆë¬¸: {target_q}
                ë‹µë³€: {transcript}
                
                ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ì„ 10ì  ë§Œì ìœ¼ë¡œ í‰ê°€í•˜ê³  í”¼ë“œë°±ì„ JSONìœ¼ë¡œ ì£¼ì„¸ìš”.
                í‚¤ê°’: logic(ë…¼ë¦¬ì„±), sincerity(ì§„ì •ì„±/êµ¬ì²´ì„±), confidence(í™•ì‹ /íƒœë„), suitability(ì „ê³µì í•©ì„±)
                ê·¸ë¦¬ê³  ì¢…í•© í”¼ë“œë°±(feedback)ë„ í¬í•¨í•˜ì„¸ìš”.
                
                JSON í˜•ì‹ ì˜ˆì‹œ:
                {{
                    "logic": 8,
                    "sincerity": 7,
                    "confidence": 6,
                    "suitability": 9,
                    "feedback": "êµ¬ì²´ì ì¸ ì‚¬ë¡€ëŠ” ì¢‹ìœ¼ë‚˜..."
                }}
                """
                res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": eval_prompt}],
                    response_format={"type": "json_object"} # JSON ëª¨ë“œ ê°•ì œ
                )
                eval_data = json.loads(res.choices[0].message.content)
                
                # === ğŸ“Š ê²°ê³¼ ë¦¬í¬íŠ¸ ===
                st.markdown("---")
                
                # [ì„¹ì…˜ 1] ë©´ì ‘ í•µì‹¬ ì§€í‘œ (ë©´ì ‘ íŠ¹í™”)
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("ë§í•˜ê¸° ì†ë„", f"{tempo:.0f} BPM", help="110~130 BPMì´ ê°€ì¥ ì‹ ë¢°ê°ì„ ì¤ë‹ˆë‹¤.")
                m2.metric("ì²«ë§ˆë”” ë°˜ì‘ ì†ë„", f"{initial_silence:.1f}ì´ˆ", delta="ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ", delta_color="inverse", help="ì§ˆë¬¸ í›„ ë‹µë³€ ì‹œì‘ê¹Œì§€ ê±¸ë¦° ì‹œê°„ì…ë‹ˆë‹¤.")
                m3.metric("ìŠµê´€ì–´(ìŒ/ì–´)", f"{total_fillers}íšŒ", delta="0íšŒê°€ ëª©í‘œ", delta_color="inverse")
                m4.metric("ë‹µë³€ ê¸¸ì´", f"{total_dur:.1f}ì´ˆ", help="40~60ì´ˆê°€ ì ë‹¹í•©ë‹ˆë‹¤.")

                st.markdown("---")
                
                # [ì„¹ì…˜ 2] ì‹œê°ì  ë¶„ì„ (ë ˆì´ë” ì°¨íŠ¸ & íŒŒì´ ì°¨íŠ¸)
                g1, g2 = st.columns(2)
                
                with g1:
                    st.subheader("ğŸ•¸ï¸ ì—­ëŸ‰ í‰ê°€ ë ˆì´ë”")
                    categories = ['ë…¼ë¦¬ì„±', 'ì§„ì •ì„±(êµ¬ì²´ì„±)', 'ìì‹ ê°(íƒœë„)', 'ì „ê³µì í•©ì„±']
                    scores = [eval_data['logic']*10, eval_data['sincerity']*10, eval_data['confidence']*10, eval_data['suitability']*10]
                    
                    fig = go.Figure(data=go.Scatterpolar(
                        r=scores, theta=categories, fill='toself', line_color='#4F46E5'
                    ))
                    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=False, height=300)
                    st.plotly_chart(fig, use_container_width=True)
                    
                with g2:
                    st.subheader("â±ï¸ ë°œí™” ì ìœ ìœ¨")
                    fig_pie = px.pie(values=[total_dur - silent_dur, silent_dur], names=["ë‹µë³€(ë§)", "ì¹¨ë¬µ(ìƒê°)"], 
                                     color_discrete_sequence=['#4F46E5', '#E0E7FF'], hole=0.4)
                    fig_pie.update_layout(height=300)
                    st.plotly_chart(fig_pie, use_container_width=True)
                    if initial_silence > 3.0:
                        st.warning(f"âš ï¸ ë‹µë³€ ì‹œì‘ê¹Œì§€ {initial_silence:.1f}ì´ˆë‚˜ ê±¸ë ¸ìŠµë‹ˆë‹¤. ë§ì„¤ì´ëŠ” ì¸ìƒì„ ì¤„ ìˆ˜ ìˆì–´ìš”.")

                # [ì„¹ì…˜ 3] ìƒì„¸ í”¼ë“œë°±
                st.subheader("ğŸ§‘â€ğŸ’¼ ì…í•™ì‚¬ì •ê´€ ì´í‰")
                st.info(eval_data['feedback'])
                
                with st.expander("ğŸ—£ï¸ ë‚´ ë‹µë³€ í…ìŠ¤íŠ¸ ë³´ê¸°"):
                    st.write(transcript)
                    if filler_counts:
                        st.write("ğŸ”´ ê°ì§€ëœ ìŠµê´€ì–´:", filler_counts)
