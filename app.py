import os
import time
import io
import difflib
import librosa
import streamlit as st
from openai import OpenAI
import plotly.graph_objects as go
import pdfplumber
from pdf2image import convert_from_bytes
import pytesseract
import json
import pandas as pd


# -------------------------------------------------
# ğŸ”‘ Streamlit & OpenAI ê¸°ë³¸ ì„¸íŒ…
# -------------------------------------------------
st.set_page_config(page_title="Spec-trum Pro", page_icon="ğŸ™ï¸", layout="wide")

# ë„¤ë¹„ê²Œì´ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "step" not in st.session_state:
    st.session_state.step = "login"

# ìƒì„±ëœ ëŒ€ë³¸ ì €ì¥ìš©
if "script" not in st.session_state:
    st.session_state.script = ""

# ë©´ì ‘ ì§ˆë¬¸ ì›ë¬¸ / ë¦¬ìŠ¤íŠ¸ / í˜„ì¬ ì¸ë±ìŠ¤ / ê¸°ë¡
if "uni_questions" not in st.session_state:
    st.session_state.uni_questions = ""
if "uni_q_list" not in st.session_state:
    st.session_state.uni_q_list = []
if "current_q_idx" not in st.session_state:
    st.session_state.current_q_idx = 0
if "interview_records" not in st.session_state:
    st.session_state.interview_records = []

# í™”ë©´ ì´ë™ í•¨ìˆ˜
def go_to(page: str):
    st.session_state.step = page
    st.rerun()

# OpenAI API í‚¤ ì„¤ì •
# - secrets.toml ì— [default] OPENAI_API_KEY="..." ë¡œ ë„£ì–´ë‘ì—ˆë‹¤ê³  ê°€ì •
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# ğŸ”‘ ì—¬ê¸°ì„œ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” secretsì—ì„œ ì½ìŒ)
client = OpenAI()


# -------------------------------------------------
# ğŸ“Š ë¶„ì„ ì—”ì§„ (í•¨ìˆ˜ë“¤)
# -------------------------------------------------
def analyze_audio_features(y, sr):
    """
    ìŒì„± ì‹ í˜¸ yì™€ ìƒ˜í”Œë§ë ˆì´íŠ¸ srì„ ë°›ì•„
    - RMS(ë³¼ë¥¨)
    - ì‹œê°„ì¶•
    - ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ
    - ì „ì²´ ê¸¸ì´
    - ì¹¨ë¬µ ë¹„ìœ¨
    - ì´ˆê¸° ì¹¨ë¬µ ì‹œê°„
    ì„ ê³„ì‚°í•œë‹¤.
    """
    rms = librosa.feature.rms(y=y)[0]
    times = librosa.times_like(rms, sr=sr)
    cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]

    # ë¹„ì¹¨ë¬µ êµ¬ê°„ íƒì§€
    non_silent = librosa.effects.split(y, top_db=25)
    non_silent_dur = sum((e - s) for s, e in non_silent) / sr
    total_dur = librosa.get_duration(y=y, sr=sr)

    if len(non_silent) > 0:
        # non_silentëŠ” ìƒ˜í”Œ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ srë¡œ ë‚˜ëˆ ì„œ ì´ˆë¡œ ë³€í™˜
        init_silence = non_silent[0][0] / sr
    else:
        init_silence = 0.0

    silence_ratio = (
        (total_dur - non_silent_dur) / total_dur if total_dur > 0 else 0.0
    )

    return times, rms, cent, total_dur, silence_ratio, init_silence


def extract_text_from_pdf(pdf_file):
    """
    pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ì‹œë„í•˜ê³ ,
    í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ pdf2image + Tesseractë¡œ OCRì„ ì‹œë„í•œë‹¤.
    """
    text = ""
    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
    except Exception:
        pass

    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ OCR ì‹œë„
    if len(text) < 50:
        pdf_file.seek(0)
        try:
            images = convert_from_bytes(pdf_file.read())
            text = ""
            for image in images:
                text += pytesseract.image_to_string(image, lang="kor+eng") + "\n"
        except Exception:
            pass

    return text


def calculate_similarity(t1, t2):
    """
    ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ë¥¼ 0~100 (%)ë¡œ ë°˜í™˜.
    """
    return difflib.SequenceMatcher(None, t1, t2).ratio() * 100


def text_to_speech_bytes(text: str) -> bytes:
    """
    OpenAI Audio TTSë¥¼ ì‚¬ìš©í•´ ì§ˆë¬¸ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
    MP3 ë°”ì´íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.
    âš ï¸ ì‚¬ìš© ì¤‘ì¸ openai-python SDK ë²„ì „ì— ë”°ë¼ model ì´ë¦„ì´ë‚˜ ì†ì„±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.
       í•„ìš”í•˜ë©´ ê³µì‹ ë¬¸ì„œë¥¼ ë³´ê³  model/í•„ë“œë¥¼ ì¡°ì •í•´ì•¼ í•¨.
    """
    try:
        response = client.audio.speech.create(
            model="gpt-4o-mini-tts",  # ë˜ëŠ” "tts-1", "gpt-4o-audio-preview" ë“± í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
            voice="alloy",
            input=text,
        )
        # ìµœì‹  SDK ê¸°ì¤€: response.read() ë˜ëŠ” stream_to_file ë“±ì„ ì œê³µ.
        # ì—¬ê¸°ì„œëŠ” bytesë¡œ ê°€ì •.
        audio_bytes = response.read()
        return audio_bytes
    except Exception as e:
        st.warning(f"TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return b""


# -------------------------------------------------
# ğŸ–¥ï¸ í™”ë©´ íë¦„ (Workflow)
# -------------------------------------------------

# [PAGE 1] ë¡œê·¸ì¸
if st.session_state.step == "login":
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.title("ğŸ”’ SPEC-TRUM")
        st.write("ì—­ëŸ‰ ì „ë‹¬ì˜ ìŠ¤í™íŠ¸ëŸ¼ì„ ë„“íˆë‹¤")

        pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        if st.button("ë¡œê·¸ì¸", use_container_width=True):
            if pw == "0601":
                st.success("ì ‘ì† ì„±ê³µ!")
                time.sleep(0.5)
                go_to("main_menu")
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ ì˜¤ë¥˜")

# [PAGE 2] ë©”ì¸ ë©”ë‰´ (ëŒ€ë¶„ë¥˜)
elif st.session_state.step == "main_menu":
    st.title("ğŸš€ ë©”ì¸ ë©”ë‰´")
    st.write("ì›í•˜ëŠ” íŠ¸ë ˆì´ë‹ ì½”ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    col1, col2 = st.columns(2)
    with col1:
        st.info("ğŸ¤ ë°œí‘œ ë§ˆìŠ¤í„°")
        if st.button("ë°œí‘œ ì¤€ë¹„ ë©”ë‰´ë¡œ ì´ë™", use_container_width=True):
            go_to("pres_menu")
    with col2:
        st.info("ğŸ“ ìƒê¸°ë¶€ ë©´ì ‘")
        if st.button("ë©´ì ‘ íŠ¸ë ˆì´ë‹ ì‹œì‘", use_container_width=True):
            go_to("inter_upload")

# =========================================================
# ğŸ¤ [ë°œí‘œ íŠ¸ë™] - ì„œë¸Œ ë©”ë‰´ ë° ë…ë¦½ ê¸°ëŠ¥ë“¤
# =========================================================

# [PAGE 3-0] ë°œí‘œ ì„œë¸Œ ë©”ë‰´ (3ê°€ì§€ ë…ë¦½ ê¸°ëŠ¥ ì„ íƒ)
elif st.session_state.step == "pres_menu":
    st.title("ğŸ¤ ë°œí‘œ ì¤€ë¹„ ë©”ë‰´")
    st.write("í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    c1, c2, c3 = st.columns(3)

    with c1:
        st.markdown("#### ğŸ“ 1. ëŒ€ë³¸ ì‘ì„±")
        st.caption("ì£¼ì œë§Œ ì£¼ë©´ AIê°€ ì¨ì¤ë‹ˆë‹¤.")
        if st.button("ëŒ€ë³¸ ì‘ì„±ê¸° ì‹¤í–‰", use_container_width=True):
            go_to("pres_1_writer")

    with c2:
        st.markdown("#### ğŸ§ 2. ëŒ€ë³¸ í‰ê°€")
        st.caption("ë‚´ê°€ ì“´ ëŒ€ë³¸ì„ í”¼ë“œë°± ë°›ìŠµë‹ˆë‹¤.")
        if st.button("ëŒ€ë³¸ í‰ê°€ê¸° ì‹¤í–‰", use_container_width=True):
            go_to("pres_2_advisor")

    with c3:
        st.markdown("#### ğŸ“Š 3. ëŠ¥ë ¥ í‰ê°€")
        st.caption("ë…¹ìŒí•˜ê³  ì†ë„, ë°œìŒ, í†¤ ë¶„ì„.")
        if st.button("ëŠ¥ë ¥ ì¸¡ì •ê¸° ì‹¤í–‰", use_container_width=True):
            go_to("pres_3_analyst")

    st.markdown("---")
    if st.button("â¬…ï¸ ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True):
        go_to("main_menu")

# [PAGE 3-1] ëŒ€ë³¸ ì‘ì„±ê¸° (Writer)
elif st.session_state.step == "pres_1_writer":
    st.title("ğŸ“ ë°œí‘œ ëŒ€ë³¸ ì‘ì„±ê¸°")

    topic = st.text_input("ì£¼ì œ", placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥ì˜ ìœ¤ë¦¬ì  ë¬¸ì œ")
    context = st.text_input("ìƒí™©", placeholder="ì˜ˆ: ìœ¤ë¦¬ ìˆ˜ì—… ë°œí‘œ")
    req = st.text_area("ìš”êµ¬ì‚¬í•­", placeholder="ì„œë¡ -ë³¸ë¡ -ê²°ë¡ , 3ë¶„ ë¶„ëŸ‰")

    if st.button("âœ¨ ëŒ€ë³¸ ìƒì„± (GPT-4o-mini)", type="primary", use_container_width=True):
        if not topic:
            st.warning("ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ì‘ì„± ì¤‘..."):
                prompt = (
                    f"ì£¼ì œ: {topic}\n"
                    f"ìƒí™©: {context}\n"
                    f"ìš”êµ¬ì‚¬í•­: {req}\n"
                    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°œí‘œ ëŒ€ë³¸ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì¤˜."
                )
                try:
                    res = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": prompt}],
                    )
                    st.session_state.script = res.choices[0].message.content
                    st.success("ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ëŒ€ë³¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    if st.session_state.script:
        st.text_area(
            "ìƒì„±ëœ ëŒ€ë³¸ (ë³µì‚¬í•´ì„œ ì“°ì„¸ìš”)",
            st.session_state.script,
            height=300,
        )

    st.markdown("---")
    if st.button("â¬…ï¸ ë°œí‘œ ë©”ë‰´ë¡œ ë³µê·€", use_container_width=True):
        go_to("pres_menu")

# [PAGE 3-2] ëŒ€ë³¸ í‰ê°€ê¸° (Advisor)
elif st.session_state.step == "pres_2_advisor":
    st.title("ğŸ§ ëŒ€ë³¸ í”¼ë“œë°±")

    default_text = st.session_state.script or ""
    user_script = st.text_area(
        "í‰ê°€ë°›ì„ ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        value=default_text,
        height=200,
    )
    user_intent = st.text_input("ì˜ë„í•˜ëŠ” ë°” (ê°•ì¡°ì )")

    if st.button("ğŸš€ í”¼ë“œë°± ë°›ê¸°", type="primary", use_container_width=True):
        if not user_script.strip():
            st.warning("ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ë¶„ì„ ì¤‘..."):
                prompt = (
                    f"ë‹¤ìŒ ë°œí‘œ ëŒ€ë³¸ì„ í‰ê°€í•´ì¤˜.\n\n"
                    f"[ëŒ€ë³¸]\n{user_script}\n\n"
                    f"[ë°œí‘œìê°€ ì „ë‹¬í•˜ê³  ì‹¶ì€ ì˜ë„]\n{user_intent}\n"
                    "- ë…¼ë¦¬ êµ¬ì¡°\n- ì „ë‹¬ë ¥\n- ì²­ì¤‘ ì´í•´ë„\n- ê°œì„ ì \nì„ ì¤‘ì‹¬ìœ¼ë¡œ í”¼ë“œë°±í•´ì¤˜."
                )
                try:
                    res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": prompt}],
                    )
                    st.info(res.choices[0].message.content)
                except Exception as e:
                    st.error(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    st.markdown("---")
    if st.button("â¬…ï¸ ë°œí‘œ ë©”ë‰´ë¡œ ë³µê·€", use_container_width=True):
        go_to("pres_menu")

# [PAGE 3-3] ëŠ¥ë ¥ í‰ê°€ê¸° (Analyst)
elif st.session_state.step == "pres_3_analyst":
    st.title("ğŸ“Š ë°œí‘œ ëŠ¥ë ¥ ì •ë°€ ë¶„ì„")
    st.caption("ëŒ€ë³¸ì´ ìˆë‹¤ë©´ ì •í™•ë„ê°€ ì¸¡ì •ë˜ê³ , ì—†ìœ¼ë©´ ì†ë„ì™€ í†¤ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")

    ref_text = st.text_area(
        "ê¸°ì¤€ ëŒ€ë³¸ (ì„ íƒì‚¬í•­ - ìˆìœ¼ë©´ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”)",
        value=st.session_state.script,
        height=100,
    )
    audio = st.audio_input("ë…¹ìŒ ì‹œì‘")

    if audio:
        with st.spinner("ì •ë°€ ë¶„ì„ ì¤‘..."):
            try:
                # ì˜¤ë””ì˜¤ ë¡œë“œ
                y, sr = librosa.load(audio, sr=None)
                times, rms, cent, tot_dur, silence_ratio, init_silence = analyze_audio_features(
                    y, sr
                )
                tempo = float(librosa.beat.beat_track(y=y, sr=sr)[0])

                # í”¼ì¹˜(f0) ì¶”ì •
                f0 = librosa.yin(
                    y,
                    fmin=librosa.note_to_hz("C2"),
                    fmax=librosa.note_to_hz("C7"),
                )
                t_pitch = librosa.times_like(f0, sr=sr)

                # STT
                audio.seek(0)
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio,
                ).text

                # ì •í™•ë„ (ëŒ€ë³¸ì´ ìˆì„ ë•Œë§Œ)
                acc = (
                    calculate_similarity(ref_text, transcript)
                    if ref_text.strip()
                    else 0.0
                )

                # ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­
                m1, m2, m3 = st.columns(3)
                m1.metric("ì†ë„", f"{tempo:.0f} BPM", delta="110~130 ê¶Œì¥")
                m2.metric(
                    "ì •í™•ë„",
                    f"{acc:.1f}%" if ref_text.strip() else "N/A",
                )
                m3.metric("ë°œí‘œ ì‹œê°„", f"{tot_dur:.1f}ì´ˆ")

                m4, m5 = st.columns(2)
                m4.metric("ì¹¨ë¬µ ë¹„ìœ¨", f"{silence_ratio * 100:.1f}%")
                m5.metric("ì´ˆê¸° ì¹¨ë¬µ ì‹œê°„", f"{init_silence:.1f}ì´ˆ")

                # ê·¸ë˜í”„ 1: ë³¼ë¥¨ ë³€í™”
                st.subheader("ëª©ì†Œë¦¬ í¬ê¸° ë³€í™” (RMS)")
                fig_vol = go.Figure()
                fig_vol.add_trace(
                    go.Scatter(
                        x=times,
                        y=rms,
                        fill="tozeroy",
                        name="Volume",
                        line=dict(color="firebrick"),
                    )
                )
                fig_vol.update_layout(
                    xaxis_title="ì‹œê°„ (s)",
                    yaxis_title="ìƒëŒ€ ë³¼ë¥¨ (RMS)",
                    template="plotly_white",
                )
                st.plotly_chart(fig_vol, use_container_width=True)

                # ê·¸ë˜í”„ 2: í”¼ì¹˜ ë³€í™”
                st.subheader("í”¼ì¹˜(ìŒë†’ì´) ë³€í™”")
                fig_pitch = go.Figure()
                fig_pitch.add_trace(
                    go.Scatter(
                        x=t_pitch,
                        y=f0,
                        name="Pitch (Hz)",
                    )
                )
                fig_pitch.update_layout(
                    xaxis_title="ì‹œê°„ (s)",
                    yaxis_title="ê¸°ì´ˆ ì£¼íŒŒìˆ˜ (Hz)",
                    template="plotly_white",
                )
                st.plotly_chart(fig_pitch, use_container_width=True)

                # ê·¸ë˜í”„ 3: ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ (ë°œìŒ/ëª…ë£Œë„ ê²½í–¥)
                st.subheader("ë°œìŒ/ëª…ë£Œë„ ê²½í–¥ (ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ)")
                t_cent = librosa.times_like(cent, sr=sr)
                fig_cent = go.Figure()
                fig_cent.add_trace(
                    go.Scatter(
                        x=t_cent,
                        y=cent,
                        name="Spectral Centroid",
                    )
                )
                fig_cent.update_layout(
                    xaxis_title="ì‹œê°„ (s)",
                    yaxis_title="ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ (Hz ëŒ€ì—­)",
                    template="plotly_white",
                )
                st.plotly_chart(fig_cent, use_container_width=True)

                with st.expander("AIê°€ ì¸ì‹í•œ ë‚´ìš© ë³´ê¸° (Whisper STT ê²°ê³¼)"):
                    st.write(transcript)

            except Exception as e:
                st.error(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    st.markdown("---")
    if st.button("â¬…ï¸ ë°œí‘œ ë©”ë‰´ë¡œ ë³µê·€", use_container_width=True):
        go_to("pres_menu")

# =========================================================
# ğŸ“ [ë©´ì ‘ íŠ¸ë™]
# =========================================================

# [PAGE 4-1] ìƒê¸°ë¶€ ì—…ë¡œë“œ
elif st.session_state.step == "inter_upload":
    st.title("ğŸ“‚ ìƒê¸°ë¶€ ì—…ë¡œë“œ")
    uploaded = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

    if uploaded:
        if st.button("ì§ˆë¬¸ ìƒì„± ë° ë‹¤ìŒ ë‹¨ê³„", type="primary", use_container_width=True):
            with st.spinner("ìƒê¸°ë¶€ë¥¼ ë¶„ì„í•´ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                text = extract_text_from_pdf(uploaded)
                if len(text) > 50:
                    prompt = (
                        "ë‹¤ìŒ ìƒê¸°ë¶€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒë¶€ ì¢…í•©ì „í˜• ë©´ì ‘ì—ì„œ ë‚˜ì˜¬ ë²•í•œ ì˜ˆìƒ ì§ˆë¬¸ 10ê°œë¥¼ "
                        "í•œêµ­ì–´ë¡œ ë§Œë“¤ì–´ì¤˜. ê° ì§ˆë¬¸ì€ í•œ ì¤„ì— í•˜ë‚˜ì”© ì¨ì¤˜.\n\n"
                        f"[ìƒê¸°ë¶€ ë‚´ìš©]\n{text[:15000]}"
                    )
                    try:
                        res = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": prompt}],
                        )
                        q_text = res.choices[0].message.content
                        st.session_state.uni_questions = q_text

                        # ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ , "?"ê°€ í¬í•¨ëœ ì¤„ë§Œ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼
                        lines = [ln.strip("-â€¢ ").strip() for ln in q_text.splitlines()]
                        q_list = [ln for ln in lines if "?" in ln]
                        st.session_state.uni_q_list = q_list
                        st.session_state.current_q_idx = 0

                        go_to("inter_practice")
                    except Exception as e:
                        st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                else:
                    st.error("í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨. ì´ë¯¸ì§€ PDFì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ìŠ¤ìº” í’ˆì§ˆì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    st.markdown("---")
    if st.button("â¬…ï¸ ë©”ì¸ ë©”ë‰´ë¡œ", use_container_width=True):
        go_to("main_menu")

# [PAGE 4-2] ë©´ì ‘ ì‹¤ì „ ì—°ìŠµ
elif st.session_state.step == "inter_practice":
    st.title("ğŸ™ï¸ ì‹¤ì „ ë©´ì ‘ íŠ¸ë ˆì´ë‹")

    questions_text = st.session_state.get(
        "uni_questions", "ì•„ì§ ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ìƒê¸°ë¶€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
    )
    q_list = st.session_state.get("uni_q_list", [])

    st.info("AI ì…í•™ì‚¬ì •ê´€ì˜ ì˜ˆìƒ ì§ˆë¬¸ (ì›ë¬¸):")
    st.write(questions_text)

    st.markdown("---")

    if not q_list:
        st.warning("ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ë‹¤ì‹œ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.")
    else:
        # í˜„ì¬ ì§ˆë¬¸ ì„ íƒ (ë²ˆí˜¸ ê¸°ë°˜)
        max_q = len(q_list)
        current_q_number = st.number_input(
            "ì—°ìŠµí•  ì§ˆë¬¸ ë²ˆí˜¸ ì„ íƒ",
            min_value=1,
            max_value=max_q,
            value=st.session_state.current_q_idx + 1,
            step=1,
        )
        st.session_state.current_q_idx = int(current_q_number) - 1
        current_question = q_list[st.session_state.current_q_idx]

        st.subheader(f"ì§ˆë¬¸ {current_q_number} / {max_q}")
        st.write(current_question)

        # íƒ€ì´ë¨¸ ì„¤ì •
        answer_seconds = st.slider("ë‹µë³€ ì‹œê°„ ì„¤ì • (ì´ˆ)", 30, 180, 60, step=10)

        # ì§ˆë¬¸ ì½ê¸° + íƒ€ì´ë¨¸ ì‹œì‘
        if st.button("â± ì§ˆë¬¸ ì½ê¸° & íƒ€ì´ë¨¸ ì‹œì‘", type="primary"):
            # ì§ˆë¬¸ TTS (ê°€ëŠ¥í•œ ê²½ìš°)
            audio_bytes = text_to_speech_bytes(current_question)
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")

            # ê°„ë‹¨ ì¹´ìš´íŠ¸ë‹¤ìš´ íƒ€ì´ë¨¸ (ì‹œê°ì  ê°€ì´ë“œ)
            timer_placeholder = st.empty()
            for remaining in range(answer_seconds, 0, -1):
                timer_placeholder.markdown(
                    f"### â³ ë‚¨ì€ ì‹œê°„: **{remaining}ì´ˆ**"
                )
                time.sleep(1)
            timer_placeholder.markdown("### âœ… ë‹µë³€ ì‹œê°„ ì¢…ë£Œ!")

        st.markdown("---")
        st.markdown("#### ğŸ¤ ë‹µë³€ ë…¹ìŒ ë° í‰ê°€")

        audio = st.audio_input("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë…¹ìŒí•˜ì„¸ìš”")

        if audio:
            with st.spinner("ë©´ì ‘ê´€ í‰ê°€ ì¤‘..."):
                try:
                    audio.seek(0)
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio,
                    ).text

                    eval_prompt = (
                        "ë„ˆëŠ” í•™ìƒë¶€ ì¢…í•©ì „í˜• ë©´ì ‘ê´€ì´ë‹¤.\n"
                        "ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë³´ê³ , ë…¼ë¦¬ì„±, ì§„ì •ì„±, ìì‹ ê°, ì§€ì›ì „ê³µ ì í•©ì„±ì„ 0~10ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , "
                        "ì§§ì€ í”¼ë“œë°±ì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼.\n\n"
                        f"[ì§ˆë¬¸]\n{current_question}\n\n"
                        f"[ë‹µë³€(STT ê²°ê³¼)]\n{transcript}\n\n"
                        'ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: {"logic": 7, "sincerity": 8, "confidence": 6, '
                        '"suitability": 7, "feedback": "í•œ ì¤„ ì´ìƒì˜ ì½”ë©˜íŠ¸"}'
                    )

                    res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": eval_prompt}],
                        response_format={"type": "json_object"},
                    )
                    data = json.loads(res.choices[0].message.content)

                    st.subheader("í‰ê°€ ë¦¬í¬íŠ¸")
                    st.write(data.get("feedback", "ë³„ë„ì˜ í”¼ë“œë°±ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."))

                    cats = ["ë…¼ë¦¬", "ì§„ì •", "ìì‹ ", "ì í•©"]
                    vals = [
                        data.get("logic", 0) * 10,
                        data.get("sincerity", 0) * 10,
                        data.get("confidence", 0) * 10,
                        data.get("suitability", 0) * 10,
                    ]

                    fig = go.Figure(
                        data=go.Scatterpolar(
                            r=vals,
                            theta=cats,
                            fill="toself",
                            name="ë©´ì ‘ ì—­ëŸ‰",
                        )
                    )
                    fig.update_layout(
                        polar=dict(radialaxis=dict(range=[0, 100])),
                        showlegend=False,
                        template="plotly_white",
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    with st.expander("AIê°€ ì¸ì‹í•œ ë‹µë³€ í…ìŠ¤íŠ¸ (Whisper ê²°ê³¼)"):
                        st.write(transcript)

                    # ğŸ‘‰ ê¸°ë¡ìš© ë ˆí¬íŠ¸ì— ì´ ì„¸ì…˜ ì¶”ê°€
                    record = {
                        "question_number": int(current_q_number),
                        "question": current_question,
                        "transcript": transcript,
                        "logic": data.get("logic", 0),
                        "sincerity": data.get("sincerity", 0),
                        "confidence": data.get("confidence", 0),
                        "suitability": data.get("suitability", 0),
                        "feedback": data.get("feedback", ""),
                    }
                    st.session_state.interview_records.append(record)

                except Exception as e:
                    st.error(f"ë©´ì ‘ í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # ëˆ„ì  ë ˆí¬íŠ¸ í‘œì‹œ
        if st.session_state.interview_records:
            st.markdown("---")
            st.markdown("### ğŸ“˜ ëˆ„ì  ë©´ì ‘ ë ˆí¬íŠ¸")

            df = pd.DataFrame(
                [
                    {
                        "ì§ˆë¬¸ë²ˆí˜¸": r["question_number"],
                        "ì§ˆë¬¸": r["question"],
                        "ë…¼ë¦¬": r["logic"],
                        "ì§„ì •ì„±": r["sincerity"],
                        "ìì‹ ê°": r["confidence"],
                        "ì í•©ì„±": r["suitability"],
                    }
                    for r in st.session_state.interview_records
                ]
            )
            st.dataframe(df, use_container_width=True)

            # ìƒì„¸ JSON ë‹¤ìš´ë¡œë“œ
            report_json = json.dumps(
                st.session_state.interview_records,
                ensure_ascii=False,
                indent=2,
            )
            st.download_button(
                "ğŸ“¥ ì „ì²´ ë©´ì ‘ ë ˆí¬íŠ¸(JSON) ë‹¤ìš´ë¡œë“œ",
                data=report_json,
                file_name="interview_report.json",
                mime="application/json",
            )

    st.markdown("---")
    if st.button("â¬…ï¸ ë‹¤ë¥¸ ìƒê¸°ë¶€ ì˜¬ë¦¬ê¸°", use_container_width=True):
        go_to("inter_upload")
