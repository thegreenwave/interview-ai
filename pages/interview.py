#ë©´ì ‘ íŠ¸ë™ (ì§ˆë¬¸ ìƒì„± + ì‹¤ì „ ëª¨ë“œ)
# pages/interview.py
import time
import json

import streamlit as st
import plotly.graph_objects as go
import pandas as pd

from ai_client import get_client
from pdf_utils import extract_text_from_pdf


client = get_client()


def text_to_speech_bytes(text: str) -> bytes:
    """
    OpenAI Audio TTSë¥¼ ì‚¬ìš©í•´ ì§ˆë¬¸ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
    MP3 ë°”ì´íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.
    âš ï¸ ì‚¬ìš© ì¤‘ì¸ openai-python SDK ë²„ì „ì— ë”°ë¼ model ì´ë¦„ì´ë‚˜ ì†ì„±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.
       í•„ìš”í•˜ë©´ ê³µì‹ ë¬¸ì„œë¥¼ ë³´ê³  model/í•„ë“œë¥¼ ì¡°ì •í•´ì•¼ í•¨.
    """
    try:
        # SDK ë²„ì „ì— ë§ê²Œ model ì´ë¦„ ìˆ˜ì • í•„ìš”í•  ìˆ˜ ìˆìŒ.
        response = client.audio.speech.create(
            model="gpt-4o-mini-tts",  # ì˜ˆì‹œ: "tts-1" ë“±ìœ¼ë¡œ êµì²´ ê°€ëŠ¥
            voice="alloy",
            input=text,
        )
        audio_bytes = response.read()
        return audio_bytes
    except Exception as e:
        st.warning(f"TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return b""


def render_interview_upload_page(go_to):
    st.title("ğŸ“‚ ìƒê¸°ë¶€ ì—…ë¡œë“œ")
    uploaded = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

    if uploaded:
        if st.button("ì§ˆë¬¸ ìƒì„± ë° ë‹¤ìŒ ë‹¨ê³„", type="primary", use_container_width=True):
            with st.spinner("ìƒê¸°ë¶€ë¥¼ ë¶„ì„í•´ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                text = extract_text_from_pdf(uploaded)
                if len(text) > 50:
                    prompt = (
                        "ë‹¤ìŒ ìƒê¸°ë¶€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒë¶€ ì¢…í•©ì „í˜• ë©´ì ‘ì—ì„œ ë‚˜ì˜¬ ë²•í•œ ì˜ˆìƒ ì§ˆë¬¸ 10ê°œë¥¼ "
                        "í•œêµ­ì–´ë¡œ ë§Œë“¤ì–´ì¤˜. ê° ì§ˆë¬¸ì€ í•œ ì¤„ì— í•˜ë‚˜ì”© ì¨ì¤˜.\n\n"
                        f"[ìƒê¸°ë¶€ ë‚´ìš©]\n{text[:15000]}"
                    )
                    try:
                        res = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": prompt}],
                        )
                        q_text = res.choices[0].message.content
                        st.session_state.uni_questions = q_text

                        # ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ , "?"ê°€ í¬í•¨ëœ ì¤„ë§Œ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼
                        lines = [ln.strip("-â€¢ ").strip() for ln in q_text.splitlines()]
                        q_list = [ln for ln in lines if "?" in ln]
                        st.session_state.uni_q_list = q_list
                        st.session_state.current_q_idx = 0
                        st.session_state.interview_records = []
                        st.session_state.interview_started = False
                        st.session_state.interview_start_time = None
                        st.session_state.interview_total_seconds = 0

                        go_to("inter_practice")
                    except Exception as e:
                        st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                else:
                    st.error("í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨. ì´ë¯¸ì§€ PDFì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ìŠ¤ìº” í’ˆì§ˆì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    st.markdown("---")
    if st.button("â¬…ï¸ ë©”ì¸ ë©”ë‰´ë¡œ", use_container_width=True):
        go_to("main_menu")


def render_interview_practice_page(go_to):
    st.title("ğŸ™ï¸ ì‹¤ì „ ë©´ì ‘ íŠ¸ë ˆì´ë‹")

    questions_text = st.session_state.get(
        "uni_questions", "ì•„ì§ ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ìƒê¸°ë¶€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
    )
    q_list = st.session_state.get("uni_q_list", [])

    with st.expander("ğŸ“„ AIê°€ ìƒì„±í•œ ì „ì²´ ì§ˆë¬¸ ì›ë¬¸ ë³´ê¸°", expanded=False):
        st.write(questions_text)

    st.markdown("---")

    if not q_list:
        st.warning("ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ë‹¤ì‹œ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.")
    else:
        # 1) ë©´ì ‘ ì„¤ì • ë‹¨ê³„
        if not st.session_state.get("interview_started", False):
            st.subheader("â± ì‹¤ì „ ë©´ì ‘ ì„¤ì •")

            st.write(f"ì´ ì§ˆë¬¸ ìˆ˜: **{len(q_list)}ê°œ**")
            total_minutes = st.slider(
                "ì´ ë©´ì ‘ ì‹œê°„(ë¶„) ì„¤ì •",
                min_value=3,
                max_value=30,
                value=10,
                step=1,
                help="ì‹¤ì œ ë©´ì ‘ì²˜ëŸ¼ ì „ì²´ ì„¸ì…˜ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤.",
            )

            if st.button("ğŸ¬ ì‹¤ì „ ë©´ì ‘ ì‹œì‘", type="primary"):
                st.session_state.interview_total_seconds = total_minutes * 60
                st.session_state.interview_start_time = time.time()
                st.session_state.interview_started = True
                st.session_state.current_q_idx = 0
                st.session_state.interview_records = []
                st.rerun()

        else:
            # 2) ì§„í–‰ ì¤‘ì¸ ë©´ì ‘ ì„¸ì…˜
            total_sec = st.session_state.get("interview_total_seconds", 0)
            start_time = st.session_state.get("interview_start_time", None)

            elapsed = time.time() - start_time if start_time else 0
            remaining = max(0, total_sec - elapsed)

            # ë‚¨ì€ ì‹œê°„ í‘œì‹œ
            min_rem = int(remaining // 60)
            sec_rem = int(remaining % 60)

            col_time, col_info = st.columns([1, 2])
            with col_time:
                st.metric(
                    "ë‚¨ì€ ì´ ë©´ì ‘ ì‹œê°„",
                    f"{min_rem:02d}:{sec_rem:02d}",
                )
            with col_info:
                st.caption(
                    "â€» ë‚¨ì€ ì‹œê°„ì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ì‹¤ì œ ë‹µë³€ ë…¹ìŒ ê¸¸ì´ëŠ” ê°•ì œ ì œí•œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )

            st.markdown("---")

            # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ ì‹œ
            if st.session_state.current_q_idx >= len(q_list):
                st.success("âœ… ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•œ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

                if st.session_state.interview_records:
                    st.markdown("### ğŸ“˜ ëˆ„ì  ë©´ì ‘ ë ˆí¬íŠ¸")

                    df = pd.DataFrame(
                        [
                            {
                                "ì§ˆë¬¸ë²ˆí˜¸": r["question_number"],
                                "ì§ˆë¬¸": r["question"],
                                "ë…¼ë¦¬": r["logic"],
                                "ì§„ì •ì„±": r["sincerity"],
                                "ìì‹ ê°": r["confidence"],
                                "ì í•©ì„±": r["suitability"],
                            }
                            for r in st.session_state.interview_records
                        ]
                    )
                    st.dataframe(df, use_container_width=True)

                    report_json = json.dumps(
                        st.session_state.interview_records,
                        ensure_ascii=False,
                        indent=2,
                    )
                    st.download_button(
                        "ğŸ“¥ ì „ì²´ ë©´ì ‘ ë ˆí¬íŠ¸(JSON) ë‹¤ìš´ë¡œë“œ",
                        data=report_json,
                        file_name="interview_report.json",
                        mime="application/json",
                    )

                if st.button("ğŸ” ê°™ì€ ì§ˆë¬¸ ì„¸íŠ¸ë¡œ ë‹¤ì‹œ ë©´ì ‘ ë³´ê¸°", use_container_width=True):
                    st.session_state.interview_started = False
                    st.session_state.interview_start_time = None
                    st.session_state.interview_total_seconds = 0
                    st.session_state.current_q_idx = 0
                    st.session_state.interview_records = []
                    st.rerun()

            else:
                # í˜„ì¬ ì§ˆë¬¸
                idx = st.session_state.current_q_idx
                current_q_number = idx + 1
                current_question = q_list[idx]

                st.subheader(f"ì§ˆë¬¸ {current_q_number} / {len(q_list)}")
                st.write(current_question)

                # ì§ˆë¬¸ì„ ìŒì„±ìœ¼ë¡œ ë“£ê³  ì‹¶ìœ¼ë©´ ì´ ë²„íŠ¼ ì‚¬ìš© (ì˜µì…˜)
                if st.button("ğŸ”Š ì§ˆë¬¸ ìŒì„±ìœ¼ë¡œ ë“£ê¸°"):
                    audio_bytes = text_to_speech_bytes(current_question)
                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3")

                st.markdown("#### ğŸ¤ ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ë…¹ìŒ")
                audio = st.audio_input("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë…¹ìŒí•˜ì„¸ìš”")

                if st.button("ğŸ§  ì´ ì§ˆë¬¸ í‰ê°€í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸°", type="primary"):
                    if audio is None:
                        st.warning("ë¨¼ì € ë‹µë³€ì„ ë…¹ìŒí•´ ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("ë©´ì ‘ê´€ í‰ê°€ ì¤‘..."):
                            try:
                                audio.seek(0)
                                transcript = client.audio.transcriptions.create(
                                    model="whisper-1",
                                    file=audio,
                                ).text

                                eval_prompt = (
                                    "ë„ˆëŠ” í•™ìƒë¶€ ì¢…í•©ì „í˜• ë©´ì ‘ê´€ì´ë‹¤.\n"
                                    "ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë³´ê³ , ë…¼ë¦¬ì„±, ì§„ì •ì„±, ìì‹ ê°, ì§€ì›ì „ê³µ ì í•©ì„±ì„ 0~10ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , "
                                    "ì§§ì€ í”¼ë“œë°±ì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼.\n\n"
                                    f"[ì§ˆë¬¸]\n{current_question}\n\n"
                                    f"[ë‹µë³€(STT ê²°ê³¼)]\n{transcript}\n\n"
                                    'ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: {"logic": 7, "sincerity": 8, "confidence": 6, '
                                    '"suitability": 7, "feedback": "í•œ ì¤„ ì´ìƒì˜ ì½”ë©˜íŠ¸"}'
                                )

                                res = client.chat.completions.create(
                                    model="gpt-4o",
                                    messages=[{"role": "user", "content": eval_prompt}],
                                    response_format={"type": "json_object"},
                                )
                                data = json.loads(res.choices[0].message.content)

                                st.subheader("ì´ë²ˆ ì§ˆë¬¸ì— ëŒ€í•œ í‰ê°€ ë¦¬í¬íŠ¸")
                                st.write(data.get("feedback", "ë³„ë„ì˜ í”¼ë“œë°±ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."))

                                cats = ["ë…¼ë¦¬", "ì§„ì •", "ìì‹ ", "ì í•©"]
                                vals = [
                                    data.get("logic", 0) * 10,
                                    data.get("sincerity", 0) * 10,
                                    data.get("confidence", 0) * 10,
                                    data.get("suitability", 0) * 10,
                                ]

                                fig = go.Figure(
                                    data=go.Scatterpolar(
                                        r=vals,
                                        theta=cats,
                                        fill="toself",
                                        name="ë©´ì ‘ ì—­ëŸ‰",
                                    )
                                )
                                fig.update_layout(
                                    polar=dict(radialaxis=dict(range=[0, 100])),
                                    showlegend=False,
                                    template="plotly_white",
                                )
                                st.plotly_chart(fig, use_container_width=True)

                                with st.expander("AIê°€ ì¸ì‹í•œ ë‹µë³€ í…ìŠ¤íŠ¸ (Whisper ê²°ê³¼)"):
                                    st.write(transcript)

                                # ê¸°ë¡ ì €ì¥
                                record = {
                                    "question_number": int(current_q_number),
                                    "question": current_question,
                                    "transcript": transcript,
                                    "logic": data.get("logic", 0),
                                    "sincerity": data.get("sincerity", 0),
                                    "confidence": data.get("confidence", 0),
                                    "suitability": data.get("suitability", 0),
                                    "feedback": data.get("feedback", ""),
                                }
                                st.session_state.interview_records.append(record)

                                # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
                                st.session_state.current_q_idx += 1
                                st.rerun()

                            except Exception as e:
                                st.error(f"ë©´ì ‘ í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    st.markdown("---")
    if st.button("â¬…ï¸ ë‹¤ë¥¸ ìƒê¸°ë¶€ ì˜¬ë¦¬ê¸°", use_container_width=True):
        st.session_state.interview_started = False
        st.session_state.interview_start_time = None
        st.session_state.interview_total_seconds = 0
        st.session_state.current_q_idx = 0
        st.session_state.interview_records = []
        go_to("inter_upload")
